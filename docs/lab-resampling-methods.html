<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 18 Lab: Resampling Methods | Statistics Learning</title>
  <meta name="description" content="Section 18 Lab: Resampling Methods | Statistics Learning" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 18 Lab: Resampling Methods | Statistics Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https//:www.ndleah.github.io/stat-learning/" />
  <meta property="og:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />
  
  <meta name="github-repo" content="ndleah/stat-learning" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 18 Lab: Resampling Methods | Statistics Learning" />
  
  
  <meta name="twitter:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/illos/favicon.ico" type="image/x-icon" />
<link rel="prev" href="the-bootstrap.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="img/illos/logo_2.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#aim-of-the-project"><i class="fa fa-check"></i><b>0.1</b> Aim Of The Project</a></li>
</ul></li>
<li class="part"><span><b>I STATISTICAL LEARNING</b></span></li>
<li class="chapter" data-level="1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html"><i class="fa fa-check"></i><b>1</b> What is Statistical Learning?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#why-estimate-f"><i class="fa fa-check"></i><b>1.1</b> Why Estimate f?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#prediction"><i class="fa fa-check"></i><b>1.1.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>1.2</b> How Do We Estimate f?</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#parametric-methods"><i class="fa fa-check"></i><b>1.2.1</b> Parametric Methods</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#non-parametric-methods"><i class="fa fa-check"></i><b>1.2.2</b> Non-Parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#the-tradeoff-between-prediction-accuracy-and-model-interpretability"><i class="fa fa-check"></i><b>1.3</b> The Tradeoff Between Prediction Accuracy and Model Interpretability</a></li>
<li class="chapter" data-level="1.4" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#supervised-vs.-unsupervised-learning"><i class="fa fa-check"></i><b>1.4</b> Supervised Vs. Unsupervised Learning</a></li>
<li class="chapter" data-level="1.5" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#regression-vs.-classification"><i class="fa fa-check"></i><b>1.5</b> Regression Vs. Classification</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html"><i class="fa fa-check"></i><b>2</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-regression-setting"><i class="fa fa-check"></i><b>2.1</b> The Regression Setting</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>2.1.1</b> Measuring the Quality of fit</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2</b> The Bias-Variance Trade-Off</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Variance-Error"><i class="fa fa-check"></i><b>2.2.1</b> Variance Error</a></li>
<li class="chapter" data-level="2.2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Bias-Error"><i class="fa fa-check"></i><b>2.2.2</b> Bias Error</a></li>
<li class="chapter" data-level="2.2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bias-variance-trafe-off"><i class="fa fa-check"></i><b>2.2.3</b> Bias-Variance Trafe-Off</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-classification-setting"><i class="fa fa-check"></i><b>2.3</b> The Classification Setting</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bayes"><i class="fa fa-check"></i><b>2.3.1</b> The Bayes Classifier</a></li>
<li class="chapter" data-level="2.3.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#KNN"><i class="fa fa-check"></i><b>2.3.2</b> K-Nearest Neighbors (KNN)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II LINEAR REGRESSION{#LINEAR-REGRESSION}</b></span></li>
<li class="chapter" data-level="3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>3.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#assessing-the-accuracy-of-the-coefficient-estimates"><i class="fa fa-check"></i><b>3.2</b> Assessing the Accuracy of the Coefficient Estimates</a>
<ul>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#population-regression-line"><i class="fa fa-check"></i>Population Regression Line</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-line"><i class="fa fa-check"></i>Least Squares Line</a></li>
<li><a href="simple-linear-regression.html#how-accurate-is-the-sample-mean-hatmu-as-an-estimate-of-population-mean-mu"><mark class="quest"> How Accurate Is The Sample Mean <span class="math inline">\(\hat{\mu}\)</span> As An Estimate Of Population Mean <span class="math inline">\(\mu\)</span> </mark></a></li>
<li><a href="simple-linear-regression.html#how-far-is-far-enough"><mark class="quest"> How Far Is Far Enough? </mark></a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#t-distribution"><i class="fa fa-check"></i>T-distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#assessing-the-accuracy-of-the-model"><i class="fa fa-check"></i><b>3.3</b> Assessing the Accuracy of the Model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residual-standard-error"><i class="fa fa-check"></i><b>3.3.1</b> Residual Standard Error</a></li>
<li class="chapter" data-level="3.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#r2-standard-error"><i class="fa fa-check"></i><b>3.3.2</b> <span class="math inline">\(R^2\)</span> Standard Error</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consideration"><i class="fa fa-check"></i><b>3.4</b> Consideration</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Response-and-Predictors-Relationships"><i class="fa fa-check"></i><b>4.1</b> Response and Predictors Relationships</a></li>
<li class="chapter" data-level="4.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Dealing-With-Large-Number-Of-Variables"><i class="fa fa-check"></i><b>4.2</b> Dealing With Large Number Of Variables</a></li>
<li class="chapter" data-level="4.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Model-Fit"><i class="fa fa-check"></i><b>4.3</b> Model Fit</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html"><i class="fa fa-check"></i><b>5</b> Other Considerations in the Regression Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-linearity-of-the-Data"><i class="fa fa-check"></i><b>5.1</b> Non-linearity of the Data</a></li>
<li class="chapter" data-level="5.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#corre-error-term"><i class="fa fa-check"></i><b>5.2</b> Correlation of Error Terms</a></li>
<li class="chapter" data-level="5.3" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-Constant-Variance-of-Error-Terms"><i class="fa fa-check"></i><b>5.3</b> Non-constant Variance of Error Terms (Heteroscedasticity)</a></li>
<li class="chapter" data-level="5.4" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Outlier"><i class="fa fa-check"></i><b>5.4</b> Outlier</a></li>
<li class="chapter" data-level="5.5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#High-Leverage-Points"><i class="fa fa-check"></i><b>5.5</b> High Leverage Points</a></li>
<li class="chapter" data-level="5.6" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Collinearity"><i class="fa fa-check"></i><b>5.6</b> Collinearity</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#correlation-matrix"><i class="fa fa-check"></i><b>5.6.1</b> Correlation Matrix</a></li>
<li class="chapter" data-level="5.6.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#variance-inflation-factor-vif"><i class="fa fa-check"></i><b>5.6.2</b> Variance Inflation Factor (VIF)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html"><i class="fa fa-check"></i><b>6</b> Case Study - Marketing Plan</a>
<ul>
<li class="chapter" data-level="6.1" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#data-overview"><i class="fa fa-check"></i><b>6.1</b> Data Overview</a></li>
<li class="chapter" data-level="6.2" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#important-questions"><i class="fa fa-check"></i><b>6.2</b> Important Questions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Lab: Linear Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>7.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="7.2" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#multiple-linear-regression-1"><i class="fa fa-check"></i><b>7.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="7.3" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#interaction-terms"><i class="fa fa-check"></i><b>7.3</b> Interaction Terms</a></li>
<li class="chapter" data-level="7.4" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#non-linear-transformations-of-the-predictors"><i class="fa fa-check"></i><b>7.4</b> Non-linear Transformations of the Predictors</a></li>
<li class="chapter" data-level="7.5" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#qualitative-predictors"><i class="fa fa-check"></i><b>7.5</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="7.6" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#writing-functions"><i class="fa fa-check"></i><b>7.6</b> Writing Functions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>8</b> Exercises</a></li>
<li class="part"><span><b>III CLASSIFICATION</b></span></li>
<li class="chapter" data-level="9" data-path="an-overview-of-classification.html"><a href="an-overview-of-classification.html"><i class="fa fa-check"></i><b>9</b> An Overview of Classification</a></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-model"><i class="fa fa-check"></i><b>10.1</b> Logistic Model</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#estimating-the-regression-coefficients"><i class="fa fa-check"></i><b>10.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>10.3</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="10.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>10.4</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html"><i class="fa fa-check"></i><b>11</b> Generative Models for Classification</a>
<ul>
<li class="chapter" data-level="11.1" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#Linear-Discriminant-Analysis"><i class="fa fa-check"></i><b>11.1</b> Linear Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#a.-when-p-1">a. When <span class="math inline">\(p\)</span> = 1</a></li>
<li><a href="generative-models-for-classification.html#b.-when-p-1">b. When <span class="math inline">\(p\)</span> &gt; 1</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#c.-problems-with-lda"><i class="fa fa-check"></i>c. Problems with LDA</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#d.-confusion-matrix"><i class="fa fa-check"></i>d. Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#QDA"><i class="fa fa-check"></i><b>11.2</b> Quadratic Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#why-is-this-important"><mark class="quest">Why is this important?</mark></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html"><i class="fa fa-check"></i><b>12</b> A Comparison of Classification Methods</a>
<ul>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-1-2-3"><i class="fa fa-check"></i>Figure for Scenarios 1, 2, 3</a></li>
<li class="chapter" data-level="12.1" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-1"><i class="fa fa-check"></i><b>12.1</b> Scenario 1</a></li>
<li class="chapter" data-level="12.2" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-2"><i class="fa fa-check"></i><b>12.2</b> Scenario 2</a></li>
<li class="chapter" data-level="12.3" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-3"><i class="fa fa-check"></i><b>12.3</b> Scenario 3</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-4-5-6"><i class="fa fa-check"></i>Figure for Scenarios 4, 5, 6</a></li>
<li class="chapter" data-level="12.4" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-4"><i class="fa fa-check"></i><b>12.4</b> Scenario 4</a></li>
<li class="chapter" data-level="12.5" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-5"><i class="fa fa-check"></i><b>12.5</b> Scenario 5</a></li>
<li class="chapter" data-level="12.6" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-6"><i class="fa fa-check"></i><b>12.6</b> Scenario 6</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#conclusion"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html"><i class="fa fa-check"></i><b>13</b> Generalized Linear Model</a>
<ul>
<li class="chapter" data-level="13.1" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#overview"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#generalized-linear-models-in-greater-generality"><i class="fa fa-check"></i><b>13.2</b> Generalized Linear Models in Greater Generality</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html"><i class="fa fa-check"></i><b>14</b> Lab: Classification Methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#the-stock-market-data"><i class="fa fa-check"></i><b>14.1</b> The Stock Market Data</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-1"><i class="fa fa-check"></i><b>14.1.1</b> Data Overview</a></li>
<li class="chapter" data-level="14.1.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#logistic-regression-1"><i class="fa fa-check"></i><b>14.1.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="14.1.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>14.1.3</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="14.1.4" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>14.1.4</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="14.1.5" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#naive-bayes"><i class="fa fa-check"></i><b>14.1.5</b> Naive Bayes</a></li>
<li class="chapter" data-level="14.1.6" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>14.1.6</b> K-Nearest Neighbors</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#the-caravan-insurance-data"><i class="fa fa-check"></i><b>14.2</b> The Caravan Insurance Data</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-2"><i class="fa fa-check"></i><b>14.2.1</b> Data Overview</a></li>
<li class="chapter" data-level="14.2.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#k-nearest-neighbors-1"><i class="fa fa-check"></i><b>14.2.2</b> K-Nearest Neighbors</a></li>
<li class="chapter" data-level="14.2.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#logistics-regression"><i class="fa fa-check"></i><b>14.2.3</b> Logistics Regression</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#bikeshare-data"><i class="fa fa-check"></i><b>14.3</b> Bikeshare Data</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-3"><i class="fa fa-check"></i><b>14.3.1</b> Data Overview</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV RESAMPLING METHOD</b></span></li>
<li class="chapter" data-level="15" data-path="an-overview-of-resampling-methods.html"><a href="an-overview-of-resampling-methods.html"><i class="fa fa-check"></i><b>15</b> An Overview of Resampling Methods</a></li>
<li class="chapter" data-level="16" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>16</b> Cross-Validation</a>
<ul>
<li class="chapter" data-level="16.1" data-path="cross-validation.html"><a href="cross-validation.html#test-and-training-error-rate"><i class="fa fa-check"></i><b>16.1</b> Test and Training Error Rate</a></li>
<li class="chapter" data-level="16.2" data-path="cross-validation.html"><a href="cross-validation.html#vsa"><i class="fa fa-check"></i><b>16.2</b> The Validation Set Approach</a></li>
<li class="chapter" data-level="16.3" data-path="cross-validation.html"><a href="cross-validation.html#LOOCV"><i class="fa fa-check"></i><b>16.3</b> Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="16.4" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>16.4</b> <span class="math inline">\(k\)</span>-Fold Cross-Validation</a></li>
<li class="chapter" data-level="16.5" data-path="cross-validation.html"><a href="cross-validation.html#bias-variance-trade-off-for-k-fold-cross-validation"><i class="fa fa-check"></i><b>16.5</b> Bias-Variance Trade-Off for k-Fold Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i><b>17</b> The Bootstrap</a></li>
<li class="chapter" data-level="18" data-path="lab-resampling-methods.html"><a href="lab-resampling-methods.html"><i class="fa fa-check"></i><b>18</b> Lab: Resampling Methods</a>
<ul>
<li class="chapter" data-level="18.1" data-path="lab-resampling-methods.html"><a href="lab-resampling-methods.html#the-validation-set-approach"><i class="fa fa-check"></i><b>18.1</b> The Validation Set Approach</a></li>
<li class="chapter" data-level="18.2" data-path="lab-resampling-methods.html"><a href="lab-resampling-methods.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>18.2</b> Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="18.3" data-path="lab-resampling-methods.html"><a href="lab-resampling-methods.html#k-fold-cross-validation-1"><i class="fa fa-check"></i><b>18.3</b> <span class="math inline">\(k\)</span>-Fold Cross-Validation</a></li>
<li class="chapter" data-level="18.4" data-path="lab-resampling-methods.html"><a href="lab-resampling-methods.html#the-bootstrap-1"><i class="fa fa-check"></i><b>18.4</b> The Bootstrap</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/ndleah/stat-learning" target="blank">View my GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<link href="style.css" rel="stylesheet">
<div class="hero-image-container"> 
  <img class= "hero-image" src="img/illos/cover.png">
</div>
<div id="lab-resampling-methods" class="section level1" number="18">
<h1><span class="header-section-number">Section 18</span> Lab: Resampling Methods</h1>
<center>
<img src="img/illos/04-lab.png" />
</center>
<p>In this lab, we explore the resampling techniques covered in this chapter. Some of the commands in this lab may take a while to run on your computer.</p>
<div id="the-validation-set-approach" class="section level2" number="18.1">
<h2><span class="header-section-number">18.1</span> The Validation Set Approach</h2>
<p>We explore the use of the validation set approach in order to estimate the test error rates that result from fitting various linear models on the <code>Auto</code> data set.</p>
<p>Before we begin, we use the <code>set.seed()</code> function in order to set a for <code>R</code>’s random number generator. It is generally a good idea to set a random seed when performing an analysis such as cross-validation that contains an element of randomness, so that the results obtained can be reproduced precisely at a later time.</p>
<p>We begin by using the <code>sample()</code> function to split the set of observations into two halves, by selecting a random subset of <span class="math inline">\(196\)</span> observations out of the original <span class="math inline">\(392\)</span> observations. We refer to these observations as the training set.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb86-1"><a href="lab-resampling-methods.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR2)</span>
<span id="cb86-2"><a href="lab-resampling-methods.html#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb86-3"><a href="lab-resampling-methods.html#cb86-3" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">392</span>, <span class="dv">196</span>)</span></code></pre></div>
<p>We then use the <code>subset</code> option in <code>lm()</code> to fit a linear regression using only the observations corresponding to the training set.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb87-1"><a href="lab-resampling-methods.html#cb87-1" aria-hidden="true" tabindex="-1"></a>lm.fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower, <span class="at">data =</span> Auto, <span class="at">subset =</span> train)</span></code></pre></div>
<p>We now use the <code>predict()</code> function to estimate the response for all <span class="math inline">\(392\)</span> observations, and we use the <code>mean()</code> function to calculate the MSE of the <span class="math inline">\(196\)</span> observations in the validation set. Note that the <code>-train</code> index below selects only the observations that are not in the training set.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb88-1"><a href="lab-resampling-methods.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Auto)</span>
<span id="cb88-2"><a href="lab-resampling-methods.html#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="do">## The following object is masked from package:ggplot2:</span></span>
<span id="cb88-3"><a href="lab-resampling-methods.html#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb88-4"><a href="lab-resampling-methods.html#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="do">##     mpg</span></span>
<span id="cb88-5"><a href="lab-resampling-methods.html#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((mpg <span class="sc">-</span> <span class="fu">predict</span>(lm.fit, Auto))[<span class="sc">-</span>train]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb88-6"><a href="lab-resampling-methods.html#cb88-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 23.26601</span></span></code></pre></div>
<p>Therefore, the estimated test MSE for the linear regression fit is <span class="math inline">\(23.27\)</span>. We can use the <code>poly()</code> function to estimate the test error for the quadratic and cubic regressions.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb89-1"><a href="lab-resampling-methods.html#cb89-1" aria-hidden="true" tabindex="-1"></a>lm.fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower, <span class="dv">2</span>), <span class="at">data =</span> Auto, <span class="at">subset =</span> train)</span>
<span id="cb89-2"><a href="lab-resampling-methods.html#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((mpg <span class="sc">-</span> <span class="fu">predict</span>(lm.fit2, Auto))[<span class="sc">-</span>train]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb89-3"><a href="lab-resampling-methods.html#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 18.71646</span></span>
<span id="cb89-4"><a href="lab-resampling-methods.html#cb89-4" aria-hidden="true" tabindex="-1"></a>lm.fit3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower, <span class="dv">3</span>), <span class="at">data =</span> Auto, <span class="at">subset =</span> train)</span>
<span id="cb89-5"><a href="lab-resampling-methods.html#cb89-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((mpg <span class="sc">-</span> <span class="fu">predict</span>(lm.fit3, Auto))[<span class="sc">-</span>train]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb89-6"><a href="lab-resampling-methods.html#cb89-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 18.79401</span></span></code></pre></div>
<p>These error rates are <span class="math inline">\(18.72\)</span> and <span class="math inline">\(18.79\)</span>, respectively. If we choose a different training set instead, then we will obtain somewhat different errors on the validation set.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb90-1"><a href="lab-resampling-methods.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb90-2"><a href="lab-resampling-methods.html#cb90-2" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">392</span>, <span class="dv">196</span>)</span>
<span id="cb90-3"><a href="lab-resampling-methods.html#cb90-3" aria-hidden="true" tabindex="-1"></a>lm.fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower, <span class="at">subset =</span> train)</span>
<span id="cb90-4"><a href="lab-resampling-methods.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((mpg <span class="sc">-</span> <span class="fu">predict</span>(lm.fit, Auto))[<span class="sc">-</span>train]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb90-5"><a href="lab-resampling-methods.html#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 25.72651</span></span>
<span id="cb90-6"><a href="lab-resampling-methods.html#cb90-6" aria-hidden="true" tabindex="-1"></a>lm.fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower, <span class="dv">2</span>), <span class="at">data =</span> Auto, <span class="at">subset =</span> train)</span>
<span id="cb90-7"><a href="lab-resampling-methods.html#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((mpg <span class="sc">-</span> <span class="fu">predict</span>(lm.fit2, Auto))[<span class="sc">-</span>train]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb90-8"><a href="lab-resampling-methods.html#cb90-8" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 20.43036</span></span>
<span id="cb90-9"><a href="lab-resampling-methods.html#cb90-9" aria-hidden="true" tabindex="-1"></a>lm.fit3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower, <span class="dv">3</span>), <span class="at">data =</span> Auto, <span class="at">subset =</span> train)</span>
<span id="cb90-10"><a href="lab-resampling-methods.html#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((mpg <span class="sc">-</span> <span class="fu">predict</span>(lm.fit3, Auto))[<span class="sc">-</span>train]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb90-11"><a href="lab-resampling-methods.html#cb90-11" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 20.38533</span></span></code></pre></div>
<p>Using this split of the observations into a training set and a validation set, we find that the validation set error rates for the models with linear, quadratic, and cubic terms are <span class="math inline">\(25.73\)</span>, <span class="math inline">\(20.43\)</span>, and <span class="math inline">\(20.39\)</span>, respectively.</p>
<p>These results are consistent with our previous findings: a model that predicts <code>mpg</code> using a quadratic function of <code>horsepower</code> performs better than a model that involves only a linear function of <code>horsepower</code>, and there is little evidence in favor of a model that uses a cubic function of <code>horsepower</code>.</p>
</div>
<div id="leave-one-out-cross-validation" class="section level2" number="18.2">
<h2><span class="header-section-number">18.2</span> Leave-One-Out Cross-Validation</h2>
<p>The LOOCV estimate can be automatically computed for any generalized linear model using the <code>glm()</code> and <code>cv.glm()</code> functions. In the lab of previous section, we used the <code>glm()</code> function to perform logistic regression by passing in the <code>family = "binomial"</code> argument. But if we use <code>glm()</code> to fit a model without passing in the <code>family</code> argument, then it performs linear regression, just like the <code>lm()</code> function.</p>
<p>In this lab, we will perform linear regression using the <code>glm()</code> function rather than the <code>lm()</code> function because the former can be used together with <code>cv.glm()</code>. The <code>cv.glm()</code> function is part of the <code>boot</code> library.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb91-1"><a href="lab-resampling-methods.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(boot)</span>
<span id="cb91-2"><a href="lab-resampling-methods.html#cb91-2" aria-hidden="true" tabindex="-1"></a>glm.fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(mpg <span class="sc">~</span> horsepower, <span class="at">data =</span> Auto)</span>
<span id="cb91-3"><a href="lab-resampling-methods.html#cb91-3" aria-hidden="true" tabindex="-1"></a>cv.err <span class="ot">&lt;-</span> <span class="fu">cv.glm</span>(Auto, glm.fit)</span>
<span id="cb91-4"><a href="lab-resampling-methods.html#cb91-4" aria-hidden="true" tabindex="-1"></a>cv.err<span class="sc">$</span>delta</span>
<span id="cb91-5"><a href="lab-resampling-methods.html#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 24.23151 24.23114</span></span></code></pre></div>
<p>The <code>cv.glm()</code> function produces a list with several components. The two numbers in the <code>delta</code> vector contain the cross-validation results. In this case the numbers are identical (up to two decimal places) and correspond to the LOOCV statistic. Below, we discuss a situation in which the two numbers differ. Our cross-validation estimate for the test error is approximately <span class="math inline">\(24.23\)</span>.</p>
<p>We can repeat this procedure for increasingly complex polynomial fits. To automate the process, we use the <code>for()</code> function to initiate a which iteratively fits polynomial regressions for polynomials of order <span class="math inline">\(i=1\)</span> to <span class="math inline">\(i=10\)</span>, computes the associated cross-validation error, and stores it in the <span class="math inline">\(i\)</span>th element of the vector <code>cv.error</code>.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb92-1"><a href="lab-resampling-methods.html#cb92-1" aria-hidden="true" tabindex="-1"></a>cv.error <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb92-2"><a href="lab-resampling-methods.html#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb92-3"><a href="lab-resampling-methods.html#cb92-3" aria-hidden="true" tabindex="-1"></a>    glm.fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower, i), <span class="at">data =</span> Auto)</span>
<span id="cb92-4"><a href="lab-resampling-methods.html#cb92-4" aria-hidden="true" tabindex="-1"></a>    cv.error[i] <span class="ot">&lt;-</span> <span class="fu">cv.glm</span>(Auto, glm.fit)<span class="sc">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb92-5"><a href="lab-resampling-methods.html#cb92-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb92-6"><a href="lab-resampling-methods.html#cb92-6" aria-hidden="true" tabindex="-1"></a>cv.error</span>
<span id="cb92-7"><a href="lab-resampling-methods.html#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] 24.23151 19.24821 19.33498 19.42443 19.03321 18.97864 18.83305 18.96115</span></span>
<span id="cb92-8"><a href="lab-resampling-methods.html#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="do">##  [9] 19.06863 19.49093</span></span></code></pre></div>
</div>
<div id="k-fold-cross-validation-1" class="section level2" number="18.3">
<h2><span class="header-section-number">18.3</span> <span class="math inline">\(k\)</span>-Fold Cross-Validation</h2>
<p>The <code>cv.glm()</code> function can also be used to implement <span class="math inline">\(k\)</span>-fold CV. Below we use <span class="math inline">\(k=10\)</span>, a common choice for <span class="math inline">\(k\)</span>, on the <code>Auto</code> data set.</p>
<p>We once again set a random seed and initialize a vector in which we will store the CV errors corresponding to the polynomial fits of orders one to ten.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb93-1"><a href="lab-resampling-methods.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">17</span>)</span>
<span id="cb93-2"><a href="lab-resampling-methods.html#cb93-2" aria-hidden="true" tabindex="-1"></a>cv.error<span class="fl">.10</span> <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb93-3"><a href="lab-resampling-methods.html#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb93-4"><a href="lab-resampling-methods.html#cb93-4" aria-hidden="true" tabindex="-1"></a>    glm.fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower, i), <span class="at">data =</span> Auto)</span>
<span id="cb93-5"><a href="lab-resampling-methods.html#cb93-5" aria-hidden="true" tabindex="-1"></a>    cv.error<span class="fl">.10</span>[i] <span class="ot">&lt;-</span> <span class="fu">cv.glm</span>(Auto, glm.fit, <span class="at">K =</span> <span class="dv">10</span>)<span class="sc">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb93-6"><a href="lab-resampling-methods.html#cb93-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-7"><a href="lab-resampling-methods.html#cb93-7" aria-hidden="true" tabindex="-1"></a>cv.error<span class="fl">.10</span></span>
<span id="cb93-8"><a href="lab-resampling-methods.html#cb93-8" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666</span></span>
<span id="cb93-9"><a href="lab-resampling-methods.html#cb93-9" aria-hidden="true" tabindex="-1"></a><span class="do">##  [9] 18.87013 20.95520</span></span></code></pre></div>
<p>Notice that the computation time is shorter than that of LOOCV. We still see little evidence that using cubic or higher-order polynomial terms leads to lower test error than simply using a quadratic fit.</p>
</div>
<div id="the-bootstrap-1" class="section level2" number="18.4">
<h2><span class="header-section-number">18.4</span> The Bootstrap</h2>
<p>We illustrate the use of the bootstrap on the <code>Auto</code> data set.</p>
<p>One of the great advantages of the bootstrap approach is that it can be
applied in almost all situations. No complicated mathematical calculations
are required. Performing a bootstrap analysis in <code>R</code> entails only two
steps. First, we must create a function that computes the statistic of
interest. Second, we use the <code>boot()</code> function, which is part of the <code>boot</code> library, to perform the bootstrap by repeatedly
sampling observations from the data set with replacement.</p>
<p>The <code>Portfolio</code> data set in the <code>ISLR2</code> package is simulated data of <span class="math inline">\(100\)</span> pairs of returns. To illustrate the use of the bootstrap on this data, we must first
create a function, <code>alpha.fn()</code>, which takes as input the <span class="math inline">\((X,Y)\)</span> data
as well as a vector indicating which observations should be used to
estimate <span class="math inline">\(\alpha\)</span>. The function then outputs the estimate for <span class="math inline">\(\alpha\)</span>
based on the selected observations.</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb94-1"><a href="lab-resampling-methods.html#cb94-1" aria-hidden="true" tabindex="-1"></a>alpha.fn <span class="ot">&lt;-</span> <span class="cf">function</span>(data, index) {</span>
<span id="cb94-2"><a href="lab-resampling-methods.html#cb94-2" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> data<span class="sc">$</span>X[index]</span>
<span id="cb94-3"><a href="lab-resampling-methods.html#cb94-3" aria-hidden="true" tabindex="-1"></a>    Y <span class="ot">&lt;-</span> data<span class="sc">$</span>Y[index]</span>
<span id="cb94-4"><a href="lab-resampling-methods.html#cb94-4" aria-hidden="true" tabindex="-1"></a>    (<span class="fu">var</span>(Y) <span class="sc">-</span> <span class="fu">cov</span>(X, Y))<span class="sc">/</span>(<span class="fu">var</span>(X) <span class="sc">+</span> <span class="fu">var</span>(Y) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">cov</span>(X, Y))</span>
<span id="cb94-5"><a href="lab-resampling-methods.html#cb94-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>This function <em>returns</em>, or outputs, an estimate for <span class="math inline">\(\alpha\)</span> to the observations indexed by the argument <code>index</code>. For instance, the following command tells <code>R</code> to estimate <span class="math inline">\(\alpha\)</span> using
all <span class="math inline">\(100\)</span> observations.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb95-1"><a href="lab-resampling-methods.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">alpha.fn</span>(Portfolio, <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>)</span>
<span id="cb95-2"><a href="lab-resampling-methods.html#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.5758321</span></span></code></pre></div>
<p>The next command uses the <code>sample()</code> function to randomly select <span class="math inline">\(100\)</span> observations from the range <span class="math inline">\(1\)</span> to <span class="math inline">\(100\)</span>, with replacement. This is equivalent
to constructing a new bootstrap data set and recomputing <span class="math inline">\(\hat{\alpha}\)</span> based on the new data set.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb96-1"><a href="lab-resampling-methods.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">7</span>)</span>
<span id="cb96-2"><a href="lab-resampling-methods.html#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="fu">alpha.fn</span>(Portfolio, <span class="fu">sample</span>(<span class="dv">100</span>, <span class="dv">100</span>, <span class="at">replace =</span> T))</span>
<span id="cb96-3"><a href="lab-resampling-methods.html#cb96-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.5385326</span></span></code></pre></div>
<p>We can implement a bootstrap analysis by performing this command many times, recording all of the corresponding estimates for <span class="math inline">\(\alpha\)</span>, and computing the resulting standard deviation.</p>
<p>However, the <code>boot()</code> function automates this approach. Below we produce <span class="math inline">\(R=1,000\)</span> bootstrap estimates for <span class="math inline">\(\alpha\)</span>.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb97-1"><a href="lab-resampling-methods.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boot</span>(Portfolio, alpha.fn, <span class="at">R =</span> <span class="dv">1000</span>)</span>
<span id="cb97-2"><a href="lab-resampling-methods.html#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb97-3"><a href="lab-resampling-methods.html#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="do">## ORDINARY NONPARAMETRIC BOOTSTRAP</span></span>
<span id="cb97-4"><a href="lab-resampling-methods.html#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb97-5"><a href="lab-resampling-methods.html#cb97-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb97-6"><a href="lab-resampling-methods.html#cb97-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb97-7"><a href="lab-resampling-methods.html#cb97-7" aria-hidden="true" tabindex="-1"></a><span class="do">## boot(data = Portfolio, statistic = alpha.fn, R = 1000)</span></span>
<span id="cb97-8"><a href="lab-resampling-methods.html#cb97-8" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb97-9"><a href="lab-resampling-methods.html#cb97-9" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb97-10"><a href="lab-resampling-methods.html#cb97-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Bootstrap Statistics :</span></span>
<span id="cb97-11"><a href="lab-resampling-methods.html#cb97-11" aria-hidden="true" tabindex="-1"></a><span class="do">##      original       bias    std. error</span></span>
<span id="cb97-12"><a href="lab-resampling-methods.html#cb97-12" aria-hidden="true" tabindex="-1"></a><span class="do">## t1* 0.5758321 0.0007959475  0.08969074</span></span></code></pre></div>
<p>The final output shows that using the original data, <span class="math inline">\(\hat{\alpha}=0.5758\)</span>,
and that the bootstrap estimate for <span class="math inline">\({\rm SE}(\hat{\alpha})\)</span> is <span class="math inline">\(0.0897\)</span>.</p>
<p>The bootstrap approach can be used to assess the variability of the coefficient estimates and predictions from a statistical learning method. Here we use the bootstrap approach in order to assess the variability of the estimates for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, the intercept and slope terms for the linear regression model that uses <code>horsepower</code> to predict <code>mpg</code> in the <code>Auto</code> data set. We will compare the estimates obtained using the bootstrap to those obtained using the formulas for <span class="math inline">\({\rm SE}(\hat{\beta}_0)\)</span> and <span class="math inline">\({\rm SE}(\hat{\beta}_1)\)</span>.</p>
<p>We first create a simple function, <code>boot.fn()</code>, which takes in the <code>Auto</code> data set as well as a set of indices for the observations, and returns the intercept and slope estimates for the linear regression model. We then apply this function to the full set of <span class="math inline">\(392\)</span> observations in order to compute the estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> on the entire data set.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb98-1"><a href="lab-resampling-methods.html#cb98-1" aria-hidden="true" tabindex="-1"></a>boot.fn <span class="ot">&lt;-</span> <span class="cf">function</span>(data, index) <span class="fu">coef</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower, <span class="at">data =</span> data, <span class="at">subset =</span> index))</span>
<span id="cb98-2"><a href="lab-resampling-methods.html#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boot.fn</span>(Auto, <span class="dv">1</span><span class="sc">:</span><span class="dv">392</span>)</span>
<span id="cb98-3"><a href="lab-resampling-methods.html#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)  horsepower </span></span>
<span id="cb98-4"><a href="lab-resampling-methods.html#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="do">##  39.9358610  -0.1578447</span></span></code></pre></div>
<p>The <code>boot.fn()</code> function can also be used in order to create bootstrap estimates for the intercept and slope terms by randomly sampling from among the observations with replacement. Here we give two examples.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb99-1"><a href="lab-resampling-methods.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb99-2"><a href="lab-resampling-methods.html#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boot.fn</span>(Auto, <span class="fu">sample</span>(<span class="dv">392</span>, <span class="dv">392</span>, <span class="at">replace =</span> T))</span>
<span id="cb99-3"><a href="lab-resampling-methods.html#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)  horsepower </span></span>
<span id="cb99-4"><a href="lab-resampling-methods.html#cb99-4" aria-hidden="true" tabindex="-1"></a><span class="do">##  40.3404517  -0.1634868</span></span>
<span id="cb99-5"><a href="lab-resampling-methods.html#cb99-5" aria-hidden="true" tabindex="-1"></a><span class="fu">boot.fn</span>(Auto, <span class="fu">sample</span>(<span class="dv">392</span>, <span class="dv">392</span>, <span class="at">replace =</span> T))</span>
<span id="cb99-6"><a href="lab-resampling-methods.html#cb99-6" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)  horsepower </span></span>
<span id="cb99-7"><a href="lab-resampling-methods.html#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="do">##  40.1186906  -0.1577063</span></span></code></pre></div>
<p>Next, we use the <code>boot()</code> function to compute the standard errors of <span class="math inline">\(1,000\)</span> bootstrap estimates for the intercept and slope terms.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb100-1"><a href="lab-resampling-methods.html#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boot</span>(Auto, boot.fn, <span class="dv">1000</span>)</span>
<span id="cb100-2"><a href="lab-resampling-methods.html#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-3"><a href="lab-resampling-methods.html#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="do">## ORDINARY NONPARAMETRIC BOOTSTRAP</span></span>
<span id="cb100-4"><a href="lab-resampling-methods.html#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-5"><a href="lab-resampling-methods.html#cb100-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-6"><a href="lab-resampling-methods.html#cb100-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb100-7"><a href="lab-resampling-methods.html#cb100-7" aria-hidden="true" tabindex="-1"></a><span class="do">## boot(data = Auto, statistic = boot.fn, R = 1000)</span></span>
<span id="cb100-8"><a href="lab-resampling-methods.html#cb100-8" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-9"><a href="lab-resampling-methods.html#cb100-9" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-10"><a href="lab-resampling-methods.html#cb100-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Bootstrap Statistics :</span></span>
<span id="cb100-11"><a href="lab-resampling-methods.html#cb100-11" aria-hidden="true" tabindex="-1"></a><span class="do">##       original        bias    std. error</span></span>
<span id="cb100-12"><a href="lab-resampling-methods.html#cb100-12" aria-hidden="true" tabindex="-1"></a><span class="do">## t1* 39.9358610  0.0544513229 0.841289790</span></span>
<span id="cb100-13"><a href="lab-resampling-methods.html#cb100-13" aria-hidden="true" tabindex="-1"></a><span class="do">## t2* -0.1578447 -0.0006170901 0.007343073</span></span></code></pre></div>
<p>This indicates that the bootstrap estimate for <span class="math inline">\({\rm SE}(\hat{\beta}_0)\)</span> is <span class="math inline">\(0.84\)</span>, and that the bootstrap estimate for <span class="math inline">\({\rm SE}(\hat{\beta}_1)\)</span> is <span class="math inline">\(0.0073\)</span>.</p>
<p>Below we compute the bootstrap standard error estimates and the standard linear regression estimates that result from fitting the quadratic model to the data. Since this model provides a good fit to the data, there is now a better correspondence between the bootstrap estimates and the standard estimates of <span class="math inline">\({\rm SE}(\hat{\beta}_0)\)</span>, <span class="math inline">\({\rm SE}(\hat{\beta}_1)\)</span> and <span class="math inline">\({\rm SE}(\hat{\beta}_2)\)</span>.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r Rchunk"><code class="sourceCode r"><span id="cb101-1"><a href="lab-resampling-methods.html#cb101-1" aria-hidden="true" tabindex="-1"></a>boot.fn <span class="ot">&lt;-</span> <span class="cf">function</span>(data, index) <span class="fu">coef</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower <span class="sc">+</span> <span class="fu">I</span>(horsepower<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> data,</span>
<span id="cb101-2"><a href="lab-resampling-methods.html#cb101-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">subset =</span> index))</span>
<span id="cb101-3"><a href="lab-resampling-methods.html#cb101-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb101-4"><a href="lab-resampling-methods.html#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="fu">boot</span>(Auto, boot.fn, <span class="dv">1000</span>)</span>
<span id="cb101-5"><a href="lab-resampling-methods.html#cb101-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb101-6"><a href="lab-resampling-methods.html#cb101-6" aria-hidden="true" tabindex="-1"></a><span class="do">## ORDINARY NONPARAMETRIC BOOTSTRAP</span></span>
<span id="cb101-7"><a href="lab-resampling-methods.html#cb101-7" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb101-8"><a href="lab-resampling-methods.html#cb101-8" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb101-9"><a href="lab-resampling-methods.html#cb101-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb101-10"><a href="lab-resampling-methods.html#cb101-10" aria-hidden="true" tabindex="-1"></a><span class="do">## boot(data = Auto, statistic = boot.fn, R = 1000)</span></span>
<span id="cb101-11"><a href="lab-resampling-methods.html#cb101-11" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb101-12"><a href="lab-resampling-methods.html#cb101-12" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb101-13"><a href="lab-resampling-methods.html#cb101-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Bootstrap Statistics :</span></span>
<span id="cb101-14"><a href="lab-resampling-methods.html#cb101-14" aria-hidden="true" tabindex="-1"></a><span class="do">##         original        bias     std. error</span></span>
<span id="cb101-15"><a href="lab-resampling-methods.html#cb101-15" aria-hidden="true" tabindex="-1"></a><span class="do">## t1* 56.900099702  3.511640e-02 2.0300222526</span></span>
<span id="cb101-16"><a href="lab-resampling-methods.html#cb101-16" aria-hidden="true" tabindex="-1"></a><span class="do">## t2* -0.466189630 -7.080834e-04 0.0324241984</span></span>
<span id="cb101-17"><a href="lab-resampling-methods.html#cb101-17" aria-hidden="true" tabindex="-1"></a><span class="do">## t3*  0.001230536  2.840324e-06 0.0001172164</span></span>
<span id="cb101-18"><a href="lab-resampling-methods.html#cb101-18" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower <span class="sc">+</span> <span class="fu">I</span>(horsepower<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> Auto))<span class="sc">$</span>coef</span>
<span id="cb101-19"><a href="lab-resampling-methods.html#cb101-19" aria-hidden="true" tabindex="-1"></a><span class="do">##                     Estimate   Std. Error   t value      Pr(&gt;|t|)</span></span>
<span id="cb101-20"><a href="lab-resampling-methods.html#cb101-20" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)     56.900099702 1.8004268063  31.60367 1.740911e-109</span></span>
<span id="cb101-21"><a href="lab-resampling-methods.html#cb101-21" aria-hidden="true" tabindex="-1"></a><span class="do">## horsepower      -0.466189630 0.0311246171 -14.97816  2.289429e-40</span></span>
<span id="cb101-22"><a href="lab-resampling-methods.html#cb101-22" aria-hidden="true" tabindex="-1"></a><span class="do">## I(horsepower^2)  0.001230536 0.0001220759  10.08009  2.196340e-21</span></span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-bootstrap.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
