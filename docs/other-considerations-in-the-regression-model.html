<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 5 Other Considerations in the Regression Model | Statistics Learning</title>
  <meta name="description" content="Section 5 Other Considerations in the Regression Model | Statistics Learning" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 5 Other Considerations in the Regression Model | Statistics Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https//:www.ndleah.github.io/stat-learning/" />
  <meta property="og:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />
  
  <meta name="github-repo" content="ndleah/stat-learning" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 5 Other Considerations in the Regression Model | Statistics Learning" />
  
  
  <meta name="twitter:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/illos/favicon.ico" type="image/x-icon" />
<link rel="prev" href="multiple-linear-regression.html"/>
<link rel="next" href="case-study---marketing-plan.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="img/illos/logo_2.png"></a></li>

<li class="divider"></li>
<li class="part"><span><b>I STATISTICAL LEARNING</b></span></li>
<li class="chapter" data-level="1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html"><i class="fa fa-check"></i><b>1</b> What is Statistical Learning?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#why-estimate-f"><i class="fa fa-check"></i><b>1.1</b> Why Estimate f?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#prediction"><i class="fa fa-check"></i><b>1.1.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>1.2</b> How Do We Estimate f?</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#parametric-methods"><i class="fa fa-check"></i><b>1.2.1</b> Parametric Methods</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#non-parametric-methods"><i class="fa fa-check"></i><b>1.2.2</b> Non-Parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#the-tradeoff-between-prediction-accuracy-and-model-interpretability"><i class="fa fa-check"></i><b>1.3</b> The Tradeoff Between Prediction Accuracy and Model Interpretability</a></li>
<li class="chapter" data-level="1.4" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#supervised-vs.-unsupervised-learning"><i class="fa fa-check"></i><b>1.4</b> Supervised Vs. Unsupervised Learning</a></li>
<li class="chapter" data-level="1.5" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#regression-vs.-classification"><i class="fa fa-check"></i><b>1.5</b> Regression Vs. Classification</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html"><i class="fa fa-check"></i><b>2</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-regression-setting"><i class="fa fa-check"></i><b>2.1</b> The Regression Setting</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>2.1.1</b> Measuring the Quality of fit</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2</b> The Bias-Variance Trade-Off</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Variance-Error"><i class="fa fa-check"></i><b>2.2.1</b> Variance Error</a></li>
<li class="chapter" data-level="2.2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Bias-Error"><i class="fa fa-check"></i><b>2.2.2</b> Bias Error</a></li>
<li class="chapter" data-level="2.2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bias-variance-trafe-off"><i class="fa fa-check"></i><b>2.2.3</b> Bias-Variance Trafe-Off</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-classification-setting"><i class="fa fa-check"></i><b>2.3</b> The Classification Setting</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bayes"><i class="fa fa-check"></i><b>2.3.1</b> The Bayes Classifier</a></li>
<li class="chapter" data-level="2.3.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#KNN"><i class="fa fa-check"></i><b>2.3.2</b> K-Nearest Neighbors (KNN)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II LINEAR REGRESSION</b></span></li>
<li class="chapter" data-level="3" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>3.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="3.2" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#assessing-the-accuracy-of-the-coefficient-estimates"><i class="fa fa-check"></i><b>3.2</b> Assessing the Accuracy of the Coefficient Estimates</a>
<ul>
<li class="chapter" data-level="" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#population-regression-line"><i class="fa fa-check"></i>Population Regression Line</a></li>
<li class="chapter" data-level="" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#least-squares-line"><i class="fa fa-check"></i>Least Squares Line</a></li>
<li><a href="LINEAR-REGRESSION.html#how-accurate-is-the-sample-mean-hatmu-as-an-estimate-of-population-mean-mu"><mark class="quest"> How Accurate Is The Sample Mean <span class="math inline">\(\hat{\mu}\)</span> As An Estimate Of Population Mean <span class="math inline">\(\mu\)</span> </mark></a></li>
<li><a href="LINEAR-REGRESSION.html#how-far-is-far-enough"><mark class="quest"> How Far Is Far Enough? </mark></a></li>
<li class="chapter" data-level="" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#t-distribution"><i class="fa fa-check"></i>T-distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#assessing-the-accuracy-of-the-model"><i class="fa fa-check"></i><b>3.3</b> Assessing the Accuracy of the Model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#residual-standard-error"><i class="fa fa-check"></i><b>3.3.1</b> Residual Standard Error</a></li>
<li class="chapter" data-level="3.3.2" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#r2-standard-error"><i class="fa fa-check"></i><b>3.3.2</b> <span class="math inline">\(R^2\)</span> Standard Error</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#consideration"><i class="fa fa-check"></i><b>3.4</b> Consideration</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Response-and-Predictors-Relationships"><i class="fa fa-check"></i><b>4.1</b> Response and Predictors Relationships</a></li>
<li class="chapter" data-level="4.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Dealing-With-Large-Number-Of-Variables"><i class="fa fa-check"></i><b>4.2</b> Dealing With Large Number Of Variables</a></li>
<li class="chapter" data-level="4.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Model-Fit"><i class="fa fa-check"></i><b>4.3</b> Model Fit</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html"><i class="fa fa-check"></i><b>5</b> Other Considerations in the Regression Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-linearity-of-the-Data"><i class="fa fa-check"></i><b>5.1</b> Non-linearity of the Data</a></li>
<li class="chapter" data-level="5.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#corre-error-term"><i class="fa fa-check"></i><b>5.2</b> Correlation of Error Terms</a></li>
<li class="chapter" data-level="5.3" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-Constant-Variance-of-Error-Terms"><i class="fa fa-check"></i><b>5.3</b> Non-constant Variance of Error Terms (Heteroscedasticity)</a></li>
<li class="chapter" data-level="5.4" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Outlier"><i class="fa fa-check"></i><b>5.4</b> Outlier</a></li>
<li class="chapter" data-level="5.5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#High-Leverage-Points"><i class="fa fa-check"></i><b>5.5</b> High Leverage Points</a></li>
<li class="chapter" data-level="5.6" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Collinearity"><i class="fa fa-check"></i><b>5.6</b> Collinearity</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#correlation-matrix"><i class="fa fa-check"></i><b>5.6.1</b> Correlation Matrix</a></li>
<li class="chapter" data-level="5.6.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#variance-inflation-factor-vif"><i class="fa fa-check"></i><b>5.6.2</b> Variance Inflation Factor (VIF)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html"><i class="fa fa-check"></i><b>6</b> Case Study - Marketing Plan</a>
<ul>
<li class="chapter" data-level="6.1" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#data-overview"><i class="fa fa-check"></i><b>6.1</b> Data Overview</a></li>
<li class="chapter" data-level="6.2" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#important-questions"><i class="fa fa-check"></i><b>6.2</b> Important Questions</a></li>
</ul></li>
<li class="part"><span><b>III CLASSIFICATION</b></span></li>
<li class="chapter" data-level="7" data-path="an-overview-of-classification.html"><a href="an-overview-of-classification.html"><i class="fa fa-check"></i><b>7</b> An Overview of Classification</a></li>
<li class="chapter" data-level="8" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-model"><i class="fa fa-check"></i><b>8.1</b> Logistic Model</a></li>
<li class="chapter" data-level="8.2" data-path="logistic-regression.html"><a href="logistic-regression.html#estimating-the-regression-coefficients"><i class="fa fa-check"></i><b>8.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="8.3" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>8.3</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="8.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>8.4</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html"><i class="fa fa-check"></i><b>9</b> Generative Models for Classification</a>
<ul>
<li class="chapter" data-level="9.1" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#Linear-Discriminant-Analysis"><i class="fa fa-check"></i><b>9.1</b> Linear Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#a.-when-p-1">a. When <span class="math inline">\(p\)</span> = 1</a></li>
<li><a href="generative-models-for-classification.html#b.-when-p-1">b. When <span class="math inline">\(p\)</span> &gt; 1</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#c.-problems-with-lda"><i class="fa fa-check"></i>c. Problems with LDA</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#d.-confusion-matrix"><i class="fa fa-check"></i>d. Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#QDA"><i class="fa fa-check"></i><b>9.2</b> Quadratic Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#why-is-this-important"><mark class="quest">Why is this important?</mark></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html"><i class="fa fa-check"></i><b>10</b> A Comparison of Classification Methods</a>
<ul>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-1-2-3"><i class="fa fa-check"></i>Figure for Scenarios 1, 2, 3</a></li>
<li class="chapter" data-level="10.1" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-1"><i class="fa fa-check"></i><b>10.1</b> Scenario 1</a></li>
<li class="chapter" data-level="10.2" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-2"><i class="fa fa-check"></i><b>10.2</b> Scenario 2</a></li>
<li class="chapter" data-level="10.3" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-3"><i class="fa fa-check"></i><b>10.3</b> Scenario 3</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-4-5-6"><i class="fa fa-check"></i>Figure for Scenarios 4, 5, 6</a></li>
<li class="chapter" data-level="10.4" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-4"><i class="fa fa-check"></i><b>10.4</b> Scenario 4</a></li>
<li class="chapter" data-level="10.5" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-5"><i class="fa fa-check"></i><b>10.5</b> Scenario 5</a></li>
<li class="chapter" data-level="10.6" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-6"><i class="fa fa-check"></i><b>10.6</b> Scenario 6</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#conclusion"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html"><i class="fa fa-check"></i><b>11</b> Generalized Linear Model</a>
<ul>
<li class="chapter" data-level="11.1" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#overview"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#generalized-linear-models-in-greater-generality"><i class="fa fa-check"></i><b>11.2</b> Generalized Linear Models in Greater Generality</a></li>
</ul></li>
<li class="part"><span><b>IV RESAMPLING METHOD</b></span></li>
<li class="chapter" data-level="12" data-path="an-overview-of-resampling-methods.html"><a href="an-overview-of-resampling-methods.html"><i class="fa fa-check"></i><b>12</b> An Overview of Resampling Methods</a></li>
<li class="chapter" data-level="13" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>13</b> Cross-Validation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="cross-validation.html"><a href="cross-validation.html#test-and-training-error-rate"><i class="fa fa-check"></i><b>13.1</b> Test and Training Error Rate</a></li>
<li class="chapter" data-level="13.2" data-path="cross-validation.html"><a href="cross-validation.html#vsa"><i class="fa fa-check"></i><b>13.2</b> The Validation Set Approach</a></li>
<li class="chapter" data-level="13.3" data-path="cross-validation.html"><a href="cross-validation.html#LOOCV"><i class="fa fa-check"></i><b>13.3</b> Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="13.4" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>13.4</b> <span class="math inline">\(k\)</span>-Fold Cross-Validation</a></li>
<li class="chapter" data-level="13.5" data-path="cross-validation.html"><a href="cross-validation.html#bias-variance-trade-off-for-k-fold-cross-validation"><i class="fa fa-check"></i><b>13.5</b> Bias-Variance Trade-Off for k-Fold Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i><b>14</b> The Bootstrap</a></li>
<li class="divider"></li>
<li><a href="https://github.com/ndleah/stat-learning" target="blank">View my GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<link href="style.css" rel="stylesheet">
<div class="hero-image-container"> 
  <img class= "hero-image" src="img/illos/cover.png">
</div>
<div id="other-considerations-in-the-regression-model" class="section level1" number="5">
<h1><span class="header-section-number">Section 5</span> Other Considerations in the Regression Model</h1>
<center>
<img src="img/illos/02-other.png" />
</center>
<p>When we fit a linear regression model, many problems can occur, to name a few:</p>
<ul>
<li><a href="other-considerations-in-the-regression-model.html#Non-linearity-of-the-Data">Non-linearity of the response-predictor relationships.</a></li>
<li><a href="other-considerations-in-the-regression-model.html#corre-error-term">Correlation of error terms.</a></li>
<li><a href="other-considerations-in-the-regression-model.html#Non-Constant-Variance-of-Error-Terms">Non-constant variance of error terms.</a></li>
<li><a href="#Outliner">Outliner.</a></li>
<li><a href="other-considerations-in-the-regression-model.html#High-Leverage-Points">High-leverage points.</a></li>
<li><a href="other-considerations-in-the-regression-model.html#Collinearity">Collinearity.</a></li>
</ul>
<div id="Non-linearity-of-the-Data" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Non-linearity of the Data</h2>
<p>The first assumption of Linear Regression is that relations between the independent and dependent variables must be linear.</p>
<p>Although this assumption is not always cited in the literature, it is logical and important to check for it. After all, if your relationships are not linear, you should not use a linear model, but rather a non-linear model of which plenty exist.</p>
<p>We can check for linear relationships easily by making a scatter plot for each independent variable with the dependent variable as in Figure <a href="other-considerations-in-the-regression-model.html#fig:residuals">5.1</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:residuals"></span>
<img src="img/107-Figure3.9-1.png" alt="Plots of residuals versus predicted (or fitted) values for the Auto data set" width="85%" />
<p class="caption">
Figure 5.1: Plots of residuals versus predicted (or fitted) values for the Auto data set
</p>
</div>
<p>In each plot, the red line is a smooth fit to the residuals, intended to make it easier to identify a trend.</p>
<ul>
<li><strong>Left:</strong> A linear regression of <code>mpg</code> on horsepower. A strong pattern in the residuals indicates non-linearity in the data.</li>
<li><strong>Right:</strong> A linear regression of <code>mpg</code> on <code>horsepower</code> and <code>horsepower2</code>. There is little pattern in the residuals.</li>
</ul>
</div>
<div id="corre-error-term" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Correlation of Error Terms</h2>
<p>If there is correlation among the error terms <span class="math inline">\(\epsilon_1, \epsilon_2,...,\epsilon_n\)</span>, then the estimated standard errors (SE) will tend to underestimate the true SE. As the result, p-value associated with the model will be lower than they should be, which could cause us to erroneously conclude that a parameter is statistically significant.</p>
<div class="tip">
<p>Such correlations frequently occur in the context of <em>time series</em> data, which consist of observations for which measurements are obtained at adjacent time points will have positively correlated errors.</p>
<p>In order to determine if this is the case for a given data set, we can plot the residuals from our model as a function of time.</p>
</div>
<p>Figure <a href="other-considerations-in-the-regression-model.html#fig:cert">5.2</a> provides an illustration. <strong>In the top panel</strong>, we see the residuals from a linear regression fit to data generated with uncorrelated errors. There is no evidence of a time-related trend in the residuals.</p>
<p>In contrast, <strong>the residuals in the bottom panel</strong> are from a data set in which adjacent errors had a correlation of 0.9. Now there is a clear pattern in the residuals—adjacent residuals tend to take on similar values.</p>
<p>Finally, <strong>the center panel</strong> illustrates a more moderate case in which the residuals had a correlation of 0.5. There is still evidence of tracking, but the pattern is less clear.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cert"></span>
<img src="img/109-Figure3.10-1.png" alt="Plots of residuals from simulated time series data sets generated with differing levels of correlation p between error terms for adjacent time" width="85%" />
<p class="caption">
Figure 5.2: Plots of residuals from simulated time series data sets generated with differing levels of correlation p between error terms for adjacent time
</p>
</div>
</div>
<div id="Non-Constant-Variance-of-Error-Terms" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Non-constant Variance of Error Terms (Heteroscedasticity)</h2>
<p><mark class="def">Heteroscedasticity</mark> in a model means that the error is constant along the values of the dependent variable.</p>
<div class="tip">
<p>One can identify non-constant variances in the errors, or heteroscedasticity, from the presence of a funnel shape in heteroscedathe residual plot.</p>
</div>
<p>An example is shown in the left-hand panel of Figure <a href="other-considerations-in-the-regression-model.html#fig:heter">5.3</a>, heteroscedasticity in which the magnitude of the residuals tends to increase with the fitted values. In each plot, the red line is a smooth fit to the residuals, intended to make it easier to identify a trend. The blue lines track the outer quantiles of the residuals, and emphasize patterns:</p>
<ul>
<li><p><strong>Left:</strong> The <em>funnel shape</em> indicates heteroscedasticity.</p></li>
<li><p><strong>Right:</strong> The response has been log transformed, and there is now no evidence of heteroscedasticity.</p></li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:heter"></span>
<img src="img/110-Figure3.11-1.png" alt=" Residual plots" width="85%" />
<p class="caption">
Figure 5.3:  Residual plots
</p>
</div>
<p>Some of the suggested solutions are:</p>
<ol style="list-style-type: decimal">
<li><p><strong><em>Do some work on your input data</em></strong> like having some variables to add or remove.</p></li>
<li><p><strong><em>Do transformations</em></strong>, like applying concave function such as <em>logistics</em> (<span class="math inline">\(logY\)</span>) or <em>square root</em> <span class="math inline">\(\sqrt{Y}\)</span>.</p></li>
<li><p>If this doesn’t change anything, you can also switch to the <strong><em>weighted least squares model</em></strong>. <em>Weighted least squares</em> is a model that can deal with unconstant variances and heteroscedasticity is therefore not a problem.</p></li>
</ol>
</div>
<div id="Outlier" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Outlier</h2>
<p>An <mark class="def">outlier</mark> is a point for which <span class="math inline">\(y_i\)</span> is far from the value predicted by model. Outliers can arise for a variety of reasons, such as incorrect recording of an observation during data collection.</p>
<p>As illustrated in Figure <a href="other-considerations-in-the-regression-model.html#fig:outlier">5.4</a>:</p>
<ul>
<li><p><strong>Left:</strong> The least squares regression line is shown in red, and the regression line after removing the outlier is shown in blue.</p></li>
<li><p><strong>Center:</strong> The residual plot clearly identifies the outlier.</p></li>
<li><p><strong>Right:</strong> The outlier has a <strong><em>studentized residual</em></strong> of 6; typically we expect values between −3 and 3.</p></li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:outlier"></span>
<img src="img/111-Figure3.12-1.png" alt="Outlier plots" width="85%" />
<p class="caption">
Figure 5.4: Outlier plots
</p>
</div>
<p>If we believe that an outlier has occurred due to an error in data collection or recording, then one solution is to simply remove the observation.</p>
</div>
<div id="High-Leverage-Points" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> High Leverage Points</h2>
<p>In contrast to outlier with unusual for response value <span class="math inline">\(y\)</span>, observations with <mark class="def">high leverage</mark> have an unusual value for <span class="math inline">\(x_i\)</span>.</p>
<p>As illustrated in Figure <a href="other-considerations-in-the-regression-model.html#fig:hlp">5.5</a>:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hlp"></span>
<img src="img/112-Figure3.13-1.png" alt="Leveraging Observations Plots" width="85%" />
<p class="caption">
Figure 5.5: Leveraging Observations Plots
</p>
</div>
<ul>
<li><p><strong>Left:</strong> Observation 41 is a high leverage point, while 20 is not. The red line is the fit to all the data, and the blue line is the fit with observation 41 removed.</p></li>
<li><p><strong>Center:</strong> The red observation is not unusual in terms of its X1 value or its X2 value, but still falls outside the bulk of the data, and hence has high leverage.</p></li>
<li><p><strong>Right:</strong> Observation 41 has a high leverage and a high residual.</p></li>
</ul>
<p>In order to quantify an observation’s leverage, we compute the <mark class="def">leverage statistic</mark> as in <a href="other-considerations-in-the-regression-model.html#eq:lev-stat">(5.1)</a>:</p>
<div class="formula">
<p><span class="math display" id="eq:lev-stat">\[\begin{equation}
\Large h_i = \frac{1}{n} + \frac{(x_i - \overline{x})^2}{\sum_{i&#39;=1}^{n}(x_i&#39; - \overline x)^2}
\tag{5.1}
\end{equation}\]</span></p>
</div>
<p>A large value of this statistic indicates an observation with high leverage.</p>
</div>
<div id="Collinearity" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Collinearity</h2>
<p><mark class="def">Collinearity</mark> refers to the situation in which two or more predictor variables are closely related to one another.</p>
<p>In order to check for collinearity, we can either use <strong><em>Correlation Matrix</em></strong> or <strong><em>Variance Inflation Factor (VIF)</em></strong>.</p>
<div id="correlation-matrix" class="section level3" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Correlation Matrix</h3>
<p>A simple way to detect collinearity is to look at the correlation matrix of the predictors. An element of this matrix that is large in absolute value indicates a pair of highly correlated variables, and therefore a collinearity problem in the data.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-7"></span>
<img src="img/unnamed.png" alt="Sample Correlation Matrix using R" width="65%" />
<p class="caption">
Figure 5.6: Sample Correlation Matrix using R
</p>
</div>
<p>Unfortunately, not all collinearity problems can be detected by inspection of the correlation matrix: it is possible for collinearity to exist between three or more variables even if no pair of variables has a particularly high correlation. We call this situation <mark class="def">multicollinearity</mark>.</p>
<p>Multicollinearity causes problems in using regression models to draw conclusions about the relationships between predictors and outcome. An individual predictor’s p-value may test non-significant even though it is important. Confidence intervals for regression coefficients in a multicollinear model may be so high that tiny changes in individual observations have a large effect on the coefficients, sometimes reversing their signs.</p>
</div>
<div id="variance-inflation-factor-vif" class="section level3" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Variance Inflation Factor (VIF)</h3>
<p>Instead of inspecting the correlation matrix, a better way to assess collinearity is to compute the <mark class="def">variance inflation factor</mark> (VIF). This can easily be calculated in <code>R</code> using software packages.</p>
<p>When faced with the problem of collinearity, there are two simple solutions:</p>
<ol style="list-style-type: decimal">
<li><p>The first is to drop one of the problematic variables from the regression.</p></li>
<li><p>The second solution is to combine the collinear variables together into a single predictor.</p></li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="case-study---marketing-plan.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
