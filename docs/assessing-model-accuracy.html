<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 2 Assessing Model Accuracy | Statistics Learning</title>
  <meta name="description" content="Section 2 Assessing Model Accuracy | Statistics Learning" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 2 Assessing Model Accuracy | Statistics Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https//:www.ndleah.github.io/stat-learning/" />
  <meta property="og:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />
  
  <meta name="github-repo" content="ndleah/stat-learning" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 2 Assessing Model Accuracy | Statistics Learning" />
  
  
  <meta name="twitter:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/illos/favicon.ico" type="image/x-icon" />
<link rel="prev" href="what-is-statistical-learning.html"/>
<link rel="next" href="simple-linear-regression.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="img/illos/logo_2.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#aim-of-the-project"><i class="fa fa-check"></i><b>0.1</b> Aim Of The Project</a></li>
</ul></li>
<li class="part"><span><b>I STATISTICAL LEARNING</b></span></li>
<li class="chapter" data-level="1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html"><i class="fa fa-check"></i><b>1</b> What is Statistical Learning?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#why-estimate-f"><i class="fa fa-check"></i><b>1.1</b> Why Estimate f?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#prediction"><i class="fa fa-check"></i><b>1.1.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>1.2</b> How Do We Estimate f?</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#parametric-methods"><i class="fa fa-check"></i><b>1.2.1</b> Parametric Methods</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#non-parametric-methods"><i class="fa fa-check"></i><b>1.2.2</b> Non-Parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#the-tradeoff-between-prediction-accuracy-and-model-interpretability"><i class="fa fa-check"></i><b>1.3</b> The Tradeoff Between Prediction Accuracy and Model Interpretability</a></li>
<li class="chapter" data-level="1.4" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#supervised-vs.-unsupervised-learning"><i class="fa fa-check"></i><b>1.4</b> Supervised Vs. Unsupervised Learning</a></li>
<li class="chapter" data-level="1.5" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#regression-vs.-classification"><i class="fa fa-check"></i><b>1.5</b> Regression Vs. Classification</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html"><i class="fa fa-check"></i><b>2</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-regression-setting"><i class="fa fa-check"></i><b>2.1</b> The Regression Setting</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>2.1.1</b> Measuring the Quality of fit</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2</b> The Bias-Variance Trade-Off</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Variance-Error"><i class="fa fa-check"></i><b>2.2.1</b> Variance Error</a></li>
<li class="chapter" data-level="2.2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Bias-Error"><i class="fa fa-check"></i><b>2.2.2</b> Bias Error</a></li>
<li class="chapter" data-level="2.2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bias-variance-trafe-off"><i class="fa fa-check"></i><b>2.2.3</b> Bias-Variance Trafe-Off</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-classification-setting"><i class="fa fa-check"></i><b>2.3</b> The Classification Setting</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bayes"><i class="fa fa-check"></i><b>2.3.1</b> The Bayes Classifier</a></li>
<li class="chapter" data-level="2.3.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#KNN"><i class="fa fa-check"></i><b>2.3.2</b> K-Nearest Neighbors (KNN)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II LINEAR REGRESSION{#LINEAR-REGRESSION}</b></span></li>
<li class="chapter" data-level="3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>3.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#assessing-the-accuracy-of-the-coefficient-estimates"><i class="fa fa-check"></i><b>3.2</b> Assessing the Accuracy of the Coefficient Estimates</a>
<ul>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#population-regression-line"><i class="fa fa-check"></i>Population Regression Line</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-line"><i class="fa fa-check"></i>Least Squares Line</a></li>
<li><a href="simple-linear-regression.html#how-accurate-is-the-sample-mean-hatmu-as-an-estimate-of-population-mean-mu"><mark class="quest"> How Accurate Is The Sample Mean <span class="math inline">\(\hat{\mu}\)</span> As An Estimate Of Population Mean <span class="math inline">\(\mu\)</span> </mark></a></li>
<li><a href="simple-linear-regression.html#how-far-is-far-enough"><mark class="quest"> How Far Is Far Enough? </mark></a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#t-distribution"><i class="fa fa-check"></i>T-distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#assessing-the-accuracy-of-the-model"><i class="fa fa-check"></i><b>3.3</b> Assessing the Accuracy of the Model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residual-standard-error"><i class="fa fa-check"></i><b>3.3.1</b> Residual Standard Error</a></li>
<li class="chapter" data-level="3.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#r2-standard-error"><i class="fa fa-check"></i><b>3.3.2</b> <span class="math inline">\(R^2\)</span> Standard Error</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consideration"><i class="fa fa-check"></i><b>3.4</b> Consideration</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Response-and-Predictors-Relationships"><i class="fa fa-check"></i><b>4.1</b> Response and Predictors Relationships</a></li>
<li class="chapter" data-level="4.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Dealing-With-Large-Number-Of-Variables"><i class="fa fa-check"></i><b>4.2</b> Dealing With Large Number Of Variables</a></li>
<li class="chapter" data-level="4.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Model-Fit"><i class="fa fa-check"></i><b>4.3</b> Model Fit</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html"><i class="fa fa-check"></i><b>5</b> Other Considerations in the Regression Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-linearity-of-the-Data"><i class="fa fa-check"></i><b>5.1</b> Non-linearity of the Data</a></li>
<li class="chapter" data-level="5.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#corre-error-term"><i class="fa fa-check"></i><b>5.2</b> Correlation of Error Terms</a></li>
<li class="chapter" data-level="5.3" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-Constant-Variance-of-Error-Terms"><i class="fa fa-check"></i><b>5.3</b> Non-constant Variance of Error Terms (Heteroscedasticity)</a></li>
<li class="chapter" data-level="5.4" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Outlier"><i class="fa fa-check"></i><b>5.4</b> Outlier</a></li>
<li class="chapter" data-level="5.5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#High-Leverage-Points"><i class="fa fa-check"></i><b>5.5</b> High Leverage Points</a></li>
<li class="chapter" data-level="5.6" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Collinearity"><i class="fa fa-check"></i><b>5.6</b> Collinearity</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#correlation-matrix"><i class="fa fa-check"></i><b>5.6.1</b> Correlation Matrix</a></li>
<li class="chapter" data-level="5.6.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#variance-inflation-factor-vif"><i class="fa fa-check"></i><b>5.6.2</b> Variance Inflation Factor (VIF)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html"><i class="fa fa-check"></i><b>6</b> Case Study - Marketing Plan</a>
<ul>
<li class="chapter" data-level="6.1" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#data-overview"><i class="fa fa-check"></i><b>6.1</b> Data Overview</a></li>
<li class="chapter" data-level="6.2" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#important-questions"><i class="fa fa-check"></i><b>6.2</b> Important Questions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Lab: Linear Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>7.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="7.2" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#multiple-linear-regression-1"><i class="fa fa-check"></i><b>7.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="7.3" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#interaction-terms"><i class="fa fa-check"></i><b>7.3</b> Interaction Terms</a></li>
<li class="chapter" data-level="7.4" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#non-linear-transformations-of-the-predictors"><i class="fa fa-check"></i><b>7.4</b> Non-linear Transformations of the Predictors</a></li>
<li class="chapter" data-level="7.5" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#qualitative-predictors"><i class="fa fa-check"></i><b>7.5</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="7.6" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#writing-functions"><i class="fa fa-check"></i><b>7.6</b> Writing Functions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>8</b> Exercises</a></li>
<li class="part"><span><b>III CLASSIFICATION</b></span></li>
<li class="chapter" data-level="9" data-path="an-overview-of-classification.html"><a href="an-overview-of-classification.html"><i class="fa fa-check"></i><b>9</b> An Overview of Classification</a></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-model"><i class="fa fa-check"></i><b>10.1</b> Logistic Model</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#estimating-the-regression-coefficients"><i class="fa fa-check"></i><b>10.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>10.3</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="10.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>10.4</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html"><i class="fa fa-check"></i><b>11</b> Generative Models for Classification</a>
<ul>
<li class="chapter" data-level="11.1" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#Linear-Discriminant-Analysis"><i class="fa fa-check"></i><b>11.1</b> Linear Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#a.-when-p-1">a. When <span class="math inline">\(p\)</span> = 1</a></li>
<li><a href="generative-models-for-classification.html#b.-when-p-1">b. When <span class="math inline">\(p\)</span> &gt; 1</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#c.-problems-with-lda"><i class="fa fa-check"></i>c. Problems with LDA</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#d.-confusion-matrix"><i class="fa fa-check"></i>d. Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#QDA"><i class="fa fa-check"></i><b>11.2</b> Quadratic Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#why-is-this-important"><mark class="quest">Why is this important?</mark></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html"><i class="fa fa-check"></i><b>12</b> A Comparison of Classification Methods</a>
<ul>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-1-2-3"><i class="fa fa-check"></i>Figure for Scenarios 1, 2, 3</a></li>
<li class="chapter" data-level="12.1" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-1"><i class="fa fa-check"></i><b>12.1</b> Scenario 1</a></li>
<li class="chapter" data-level="12.2" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-2"><i class="fa fa-check"></i><b>12.2</b> Scenario 2</a></li>
<li class="chapter" data-level="12.3" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-3"><i class="fa fa-check"></i><b>12.3</b> Scenario 3</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-4-5-6"><i class="fa fa-check"></i>Figure for Scenarios 4, 5, 6</a></li>
<li class="chapter" data-level="12.4" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-4"><i class="fa fa-check"></i><b>12.4</b> Scenario 4</a></li>
<li class="chapter" data-level="12.5" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-5"><i class="fa fa-check"></i><b>12.5</b> Scenario 5</a></li>
<li class="chapter" data-level="12.6" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-6"><i class="fa fa-check"></i><b>12.6</b> Scenario 6</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#conclusion"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html"><i class="fa fa-check"></i><b>13</b> Generalized Linear Model</a>
<ul>
<li class="chapter" data-level="13.1" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#overview"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#generalized-linear-models-in-greater-generality"><i class="fa fa-check"></i><b>13.2</b> Generalized Linear Models in Greater Generality</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html"><i class="fa fa-check"></i><b>14</b> Lab: Classification Methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#the-stock-market-data"><i class="fa fa-check"></i><b>14.1</b> The Stock Market Data</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-1"><i class="fa fa-check"></i><b>14.1.1</b> Data Overview</a></li>
<li class="chapter" data-level="14.1.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#logistic-regression-1"><i class="fa fa-check"></i><b>14.1.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="14.1.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>14.1.3</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="14.1.4" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>14.1.4</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="14.1.5" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#naive-bayes"><i class="fa fa-check"></i><b>14.1.5</b> Naive Bayes</a></li>
<li class="chapter" data-level="14.1.6" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>14.1.6</b> K-Nearest Neighbors</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#the-caravan-insurance-data"><i class="fa fa-check"></i><b>14.2</b> The Caravan Insurance Data</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-2"><i class="fa fa-check"></i><b>14.2.1</b> Data Overview</a></li>
<li class="chapter" data-level="14.2.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#k-nearest-neighbors-1"><i class="fa fa-check"></i><b>14.2.2</b> K-Nearest Neighbors</a></li>
<li class="chapter" data-level="14.2.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#logistics-regression"><i class="fa fa-check"></i><b>14.2.3</b> Logistics Regression</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#bikeshare-data"><i class="fa fa-check"></i><b>14.3</b> Bikeshare Data</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-3"><i class="fa fa-check"></i><b>14.3.1</b> Data Overview</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV RESAMPLING METHOD</b></span></li>
<li class="chapter" data-level="15" data-path="an-overview-of-resampling-methods.html"><a href="an-overview-of-resampling-methods.html"><i class="fa fa-check"></i><b>15</b> An Overview of Resampling Methods</a></li>
<li class="chapter" data-level="16" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>16</b> Cross-Validation</a>
<ul>
<li class="chapter" data-level="16.1" data-path="cross-validation.html"><a href="cross-validation.html#test-and-training-error-rate"><i class="fa fa-check"></i><b>16.1</b> Test and Training Error Rate</a></li>
<li class="chapter" data-level="16.2" data-path="cross-validation.html"><a href="cross-validation.html#the-validation-set-approach"><i class="fa fa-check"></i><b>16.2</b> The Validation Set Approach</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/ndleah/stat-learning" target="blank">View my GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<link href="style.css" rel="stylesheet">
<div class="hero-image-container"> 
  <img class= "hero-image" src="img/illos/cover.png">
</div>
<div id="assessing-model-accuracy" class="section level1" number="2">
<h1><span class="header-section-number">Section 2</span> Assessing Model Accuracy</h1>
<center>
<img src="img/illos/01-accuracy.png" />
</center>
<blockquote>
<p><em>"<strong>There is no free lunch in statistics"</strong></em></p>
</blockquote>
<p>No one method dominates all others over all possible data sets. This section introduce some common ways to assess the accuracy of a model to select a statistical learning procedure for a specific data set.</p>
<div id="the-regression-setting" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> The Regression Setting</h2>
<div id="measuring-the-quality-of-fit" class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Measuring the Quality of fit</h3>
<p>In order to evaluate the performance of a model, we need to measure how well its predictions actually match the observed data. In the regression setting, the most commonly used measure is the <mark class="def">mean squared error</mark> (MSE) as illustrated in <a href="assessing-model-accuracy.html#eq:mse">(2.1)</a>:</p>
<div class="formula">
<p><span class="math display" id="eq:mse">\[\begin{equation}
\Large MSE = \frac{1}{n}\sum_{i = 1}^{n} (y_{n} - \hat{f}(x_{i})^2
\tag{2.1} 
\end{equation}\]</span></p>
</div>
<p>given by where <span class="math inline">\(\hat{f}(x_{i}\)</span> is the prediction that <span class="math inline">\(\hat{f}\)</span> gives for the <span class="math inline">\(i\)</span>th observations.</p>
<p>The MSE will be small if the predicted responses are very close to the true response, and will be large if for some observations, the predicted and true responses differ substantially.</p>
<p><br></p>
<div class="def">
<div class="split">
<div class="split1">
<p><mark class="def">Training MSE</mark></p>
<p>computed using the training data that was used to fit the model.</p>
</div>
<div class="split2">
<p><mark class="def">Test MSE</mark></p>
<p>computed using the previously unseen test observation not used to train the statistical learning method.</p>
</div>
</div>
</div>
<p></br></p>
<p>When a given method yields a small training MSE but a large test MSE, we are said to be <em>overfitting</em> the data. When we overfit the training data, the test MSE will be very large because the supposed patterns that the method found in the training data simply don’t exist in the test data.</p>
</div>
</div>
<div id="the-bias-variance-trade-off" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> The Bias-Variance Trade-Off</h2>
<div id="Variance-Error" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Variance Error</h3>
<p><mark class="def">Variance</mark> is the amount that the estimate of <span class="math inline">\(\hat{f}\)</span> will change if different training data was used.</p>
<p>Ideally, it should not change too much from one training dataset to the next, meaning that the algorithm is good at picking out the hidden underlying mapping between the inputs and the output variables.</p>
<div class="hat">
<p>Examples of <u><strong>low-variance</u></strong> machine learning algorithms include: <mark class="example">Linear Regression</mark>, <mark class="example">Linear Discriminant Analysis</mark> and <mark class="example">Logistic Regression</mark>.</p>
<p>Examples of <u><strong>high-variance</u></strong> machine learning algorithms include: <mark class="example">Decision Trees</mark>, <mark class="example">k-Nearest Neighbors</mark> and <mark class="example">Support Vector Machines</mark>.</p>
</div>
</div>
<div id="Bias-Error" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Bias Error</h3>
<p><mark class="def">Bias</mark> are the simplifying assumptions made by a model to make the target function easier to learn.</p>
<p>Generally, linear algorithms have a high bias making them fast to learn and easier to understand but generally less flexible. In turn, they have lower predictive performance on complex problems that fail to meet the simplifying assumptions of the algorithms bias.</p>
<p><br></p>
<div class="def">
<div class="split">
<div class="split1">
<p><mark class="def">Low Bias</mark></p>
<p>Suggests less assumptions about the form of the target function.</p>
</div>
<div class="split2">
<p><mark class="def">High-Bias</mark></p>
<p>Suggests more assumptions about the form of the target function.</p>
</div>
</div>
</div>
<p></br></p>
<div class="hat">
<p>Examples of <u><strong>low-bias</u></strong> machine learning algorithms include: <mark class="example">Decision Trees</mark>, <mark class="example">k-Nearest Neighbors</mark> and <mark class="example">Support Vector Machines</mark>.</p>
<p>Examples of <u><strong>high-bias</u></strong> machine learning algorithms include: <mark class="example">Linear Regression</mark>, <mark class="example">Linear Discriminant Analysis</mark> and <mark class="example">Logistic Regression</mark>.</p>
</div>
</div>
<div id="bias-variance-trafe-off" class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Bias-Variance Trafe-Off</h3>
<p>The goal of any supervised machine learning algorithm is to achieve <em>low bias</em> and <em>low variance</em>. In turn the algorithm should achieve good prediction performance.</p>
<ul>
<li><mark class="def">Linear machine learning algorithms</mark> often have a high bias but a low variance.</li>
<li><mark class="def">Nonlinear machine learning algorithms</mark> often have a low bias but a high variance.</li>
<li>The parameterization of machine learning algorithms is often a battle to <u><strong>balance out bias and variance</u></strong>.</li>
</ul>
</div>
</div>
<div id="the-classification-setting" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> The Classification Setting</h2>
<p>The most common approach for quantifying the accuracy of our estimate <span class="math inline">\(\hat{f}\)</span> is the <em>training error</em> rate, the proportion of mistakes that are made if we apply our estimate <span class="math inline">\(\hat{f}\)</span> to the training observations:</p>
<div class="formula">
<p><span class="math display" id="eq:ter">\[\begin{equation}
\frac{1}{n}\sum_{i = 1}^{n} I (y_{i} \neq \hat{y_{i}})
\tag{2.2} 
\end{equation}\]</span></p>
</div>
<p>Whereas:</p>
<ul>
<li><p><span class="math inline">\(\hat{y_{i}}\)</span>: the predicted class label for the <span class="math inline">\(i\)</span>th observation using <span class="math inline">\(\hat{f}\)</span></p></li>
<li><p><span class="math inline">\(I (y_{i} \neq \hat{y_{i}})\)</span>: an <em>indicator variable</em> that equal <strong>1</strong> if <span class="math inline">\(y_{i} \neq \hat{y_{i}}\)</span> and <strong>0</strong> if <span class="math inline">\(y_{i} = \hat{y_{i}}\)</span>. If:</p>
<ul>
<li><p><span class="math inline">\(I (y_{i} \neq \hat{y_{i}}) = 0\)</span>: correct classification</p></li>
<li><p><span class="math inline">\(I (y_{i} \neq \hat{y_{i}}) \neq 0\)</span>: incorrect classification (misclassified)</p></li>
</ul></li>
</ul>
<p>A good classifier is one for which the <em>test error</em> is smallest where the <em>test error</em> rate associated with a set of test observations of the from <span class="math inline">\((x_{0}, y_{0})\)</span>.</p>
<div id="bayes" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> The Bayes Classifier</h3>
<p>This algorithm is called Naïve because it works on the naïve assumption that the features are independent. <mark class="def">Naïve Bayes Classifier</mark> works with principle of <strong>Bayes Theorem</strong>.</p>
<blockquote>
<p>Conditional probability of an event <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>, <span class="math inline">\(P(A|B)\)</span> is the probability of <span class="math inline">\(A\)</span> given that <span class="math inline">\(B\)</span> has already occurred. It is often defined as the ratio of joint probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> (probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occurring together) to the marginal probability of <span class="math inline">\(A\)</span> (probability of event <span class="math inline">\(A\)</span>)</p>
</blockquote>
<div class="tip">
<p><u><strong>Pros</u></strong></p>
<ul>
<li>Easy to implement</li>
<li>Performs reasonably well with noisy data</li>
</ul>
<p><u><strong>Cons</u></strong></p>
<ul>
<li>Poor performance with continuous features</li>
<li>Assumption that features are independent is risky</li>
</ul>
</div>
</div>
<div id="KNN" class="section level3" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> K-Nearest Neighbors (KNN)</h3>
<p><mark class="def">K-Nearest neighbors</mark> (KNN) algorithm can be used to solve both classification and regression problems. When algorithms such as Naïve Bayes Classifier uses probabilities from training samples for predictions, KNN is Lazy learner that does not create any model in advance. The just find the closest based on feature similarity.</p>
<div class="tip">
<p><u><strong>Pros</u></strong></p>
<ul>
<li>Easy to implement</li>
<li>No assumptions involved</li>
</ul>
<p><u><strong>Cons</u></strong></p>
<ul>
<li>Optimal K is always a challenge</li>
<li>Lazy learner- computationally expensive</li>
</ul>
</div>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="what-is-statistical-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="simple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
