<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 4 Simple Linear Regression | Statistics Learning</title>
  <meta name="description" content="Section 4 Simple Linear Regression | Statistics Learning" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 4 Simple Linear Regression | Statistics Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https//:www.ndleah.github.io/stat-learning/" />
  <meta property="og:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />
  
  <meta name="github-repo" content="ndleah/stat-learning" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 4 Simple Linear Regression | Statistics Learning" />
  
  
  <meta name="twitter:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/illos/favicon.ico" type="image/x-icon" />
<link rel="prev" href="assessing-model-accuracy.html"/>
<link rel="next" href="multiple-linear-regression.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="img/illos/logo_2.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#about"><i class="fa fa-check"></i><b>1.1</b> About</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#feedback"><i class="fa fa-check"></i><b>1.2</b> Feedback</a></li>
</ul></li>
<li class="part"><span><b>I STATISTICAL LEARNING</b></span></li>
<li class="chapter" data-level="2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html"><i class="fa fa-check"></i><b>2</b> What is Statistical Learning?</a>
<ul>
<li class="chapter" data-level="2.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#why-estimate-f"><i class="fa fa-check"></i><b>2.1</b> Why Estimate f?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#prediction"><i class="fa fa-check"></i><b>2.1.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>2.2</b> How Do We Estimate f?</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#parametric-methods"><i class="fa fa-check"></i><b>2.2.1</b> Parametric Methods</a></li>
<li class="chapter" data-level="2.2.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#non-parametric-methods"><i class="fa fa-check"></i><b>2.2.2</b> Non-Parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#the-tradeoff-between-prediction-accuracy-and-model-interpretability"><i class="fa fa-check"></i><b>2.3</b> The Tradeoff Between Prediction Accuracy and Model Interpretability</a></li>
<li class="chapter" data-level="2.4" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#supervised-vs.-unsupervised-learning"><i class="fa fa-check"></i><b>2.4</b> Supervised Vs. Unsupervised Learning</a></li>
<li class="chapter" data-level="2.5" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#regression-vs.-classification"><i class="fa fa-check"></i><b>2.5</b> Regression Vs. Classification</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html"><i class="fa fa-check"></i><b>3</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="3.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-regression-setting"><i class="fa fa-check"></i><b>3.1</b> The Regression Setting</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>3.1.1</b> Measuring the Quality of fit</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>3.2</b> The Bias-Variance Trade-Off</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Variance-Error"><i class="fa fa-check"></i><b>3.2.1</b> Variance Error</a></li>
<li class="chapter" data-level="3.2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Bias-Error"><i class="fa fa-check"></i><b>3.2.2</b> Bias Error</a></li>
<li class="chapter" data-level="3.2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bias-variance-trafe-off"><i class="fa fa-check"></i><b>3.2.3</b> Bias-Variance Trafe-Off</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-classification-setting"><i class="fa fa-check"></i><b>3.3</b> The Classification Setting</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bayes"><i class="fa fa-check"></i><b>3.3.1</b> The Bayes Classifier</a></li>
<li class="chapter" data-level="3.3.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#KNN"><i class="fa fa-check"></i><b>3.3.2</b> K-Nearest Neighbors (KNN)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II LINEAR REGRESSION</b></span></li>
<li class="chapter" data-level="4" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html"><i class="fa fa-check"></i><b>4</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>4.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="4.2" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#assessing-the-accuracy-of-the-coefficient-estimates"><i class="fa fa-check"></i><b>4.2</b> Assessing the Accuracy of the Coefficient Estimates</a>
<ul>
<li class="chapter" data-level="" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#population-regression-line"><i class="fa fa-check"></i>Population Regression Line</a></li>
<li class="chapter" data-level="" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#least-squares-line"><i class="fa fa-check"></i>Least Squares Line</a></li>
<li><a href="LINEAR-REGRESSION.html#how-accurate-is-the-sample-mean-hatmu-as-an-estimate-of-population-mean-mu"><mark class="quest"> How Accurate Is The Sample Mean <span class="math inline">\(\hat{\mu}\)</span> As An Estimate Of Population Mean <span class="math inline">\(\mu\)</span> </mark></a></li>
<li><a href="LINEAR-REGRESSION.html#how-far-is-far-enough"><mark class="quest"> How Far Is Far Enough? </mark></a></li>
<li class="chapter" data-level="" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#t-distribution"><i class="fa fa-check"></i>T-distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#assessing-the-accuracy-of-the-model"><i class="fa fa-check"></i><b>4.3</b> Assessing the Accuracy of the Model</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#residual-standard-error"><i class="fa fa-check"></i><b>4.3.1</b> Residual Standard Error</a></li>
<li class="chapter" data-level="4.3.2" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#r2-standard-error"><i class="fa fa-check"></i><b>4.3.2</b> <span class="math inline">\(R^2\)</span> Standard Error</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="LINEAR-REGRESSION.html"><a href="LINEAR-REGRESSION.html#consideration"><i class="fa fa-check"></i><b>4.4</b> Consideration</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>5</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Response-and-Predictors-Relationships"><i class="fa fa-check"></i><b>5.1</b> Response and Predictors Relationships</a></li>
<li class="chapter" data-level="5.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Dealing-With-Large-Number-Of-Variables"><i class="fa fa-check"></i><b>5.2</b> Dealing With Large Number Of Variables</a></li>
<li class="chapter" data-level="5.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Model-Fit"><i class="fa fa-check"></i><b>5.3</b> Model Fit</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html"><i class="fa fa-check"></i><b>6</b> Other Considerations in the Regression Model</a>
<ul>
<li class="chapter" data-level="6.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-linearity-of-the-Data"><i class="fa fa-check"></i><b>6.1</b> Non-linearity of the Data</a></li>
<li class="chapter" data-level="6.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#corre-error-term"><i class="fa fa-check"></i><b>6.2</b> Correlation of Error Terms</a></li>
<li class="chapter" data-level="6.3" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-Constant-Variance-of-Error-Terms"><i class="fa fa-check"></i><b>6.3</b> Non-constant Variance of Error Terms (Heteroscedasticity)</a></li>
<li class="chapter" data-level="6.4" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Outlier"><i class="fa fa-check"></i><b>6.4</b> Outlier</a></li>
<li class="chapter" data-level="6.5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#High-Leverage-Points"><i class="fa fa-check"></i><b>6.5</b> High Leverage Points</a></li>
<li class="chapter" data-level="6.6" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Collinearity"><i class="fa fa-check"></i><b>6.6</b> Collinearity</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#correlation-matrix"><i class="fa fa-check"></i><b>6.6.1</b> Correlation Matrix</a></li>
<li class="chapter" data-level="6.6.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#variance-inflation-factor-vif"><i class="fa fa-check"></i><b>6.6.2</b> Variance Inflation Factor (VIF)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html"><i class="fa fa-check"></i><b>7</b> Case Study - Marketing Plan</a>
<ul>
<li class="chapter" data-level="7.1" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#data-overview"><i class="fa fa-check"></i><b>7.1</b> Data Overview</a></li>
<li class="chapter" data-level="7.2" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#important-questions"><i class="fa fa-check"></i><b>7.2</b> Important Questions</a></li>
</ul></li>
<li class="part"><span><b>III CLASSIFICATION</b></span></li>
<li class="chapter" data-level="8" data-path="an-overview-of-classification.html"><a href="an-overview-of-classification.html"><i class="fa fa-check"></i><b>8</b> An Overview of Classification</a></li>
<li class="chapter" data-level="9" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>9</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-model"><i class="fa fa-check"></i><b>9.1</b> Logistic Model</a></li>
<li class="chapter" data-level="9.2" data-path="logistic-regression.html"><a href="logistic-regression.html#estimating-the-regression-coefficients"><i class="fa fa-check"></i><b>9.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="9.3" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>9.3</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="9.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>9.4</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html"><i class="fa fa-check"></i><b>10</b> Generative Models for Classification</a>
<ul>
<li class="chapter" data-level="10.1" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#Linear-Discriminant-Analysis"><i class="fa fa-check"></i><b>10.1</b> Linear Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#a.-when-p-1">a. When <span class="math inline">\(p\)</span> = 1</a></li>
<li><a href="generative-models-for-classification.html#b.-when-p-1">b. When <span class="math inline">\(p\)</span> &gt; 1</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#c.-problems-with-lda"><i class="fa fa-check"></i>c. Problems with LDA</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#d.-confusion-matrix"><i class="fa fa-check"></i>d. Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#QDA"><i class="fa fa-check"></i><b>10.2</b> Quadratic Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#why-is-this-important"><mark class="quest">Why is this important?</mark></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html"><i class="fa fa-check"></i><b>11</b> A Comparison of Classification Methods</a>
<ul>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-1-2-3"><i class="fa fa-check"></i>Figure for Scenarios 1, 2, 3</a></li>
<li class="chapter" data-level="11.1" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-1"><i class="fa fa-check"></i><b>11.1</b> Scenario 1</a></li>
<li class="chapter" data-level="11.2" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-2"><i class="fa fa-check"></i><b>11.2</b> Scenario 2</a></li>
<li class="chapter" data-level="11.3" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-3"><i class="fa fa-check"></i><b>11.3</b> Scenario 3</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-4-5-6"><i class="fa fa-check"></i>Figure for Scenarios 4, 5, 6</a></li>
<li class="chapter" data-level="11.4" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-4"><i class="fa fa-check"></i><b>11.4</b> Scenario 4</a></li>
<li class="chapter" data-level="11.5" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-5"><i class="fa fa-check"></i><b>11.5</b> Scenario 5</a></li>
<li class="chapter" data-level="11.6" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-6"><i class="fa fa-check"></i><b>11.6</b> Scenario 6</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#conclusion"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html"><i class="fa fa-check"></i><b>12</b> Generalized Linear Model</a>
<ul>
<li class="chapter" data-level="12.1" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#overview"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#generalized-linear-models-in-greater-generality"><i class="fa fa-check"></i><b>12.2</b> Generalized Linear Models in Greater Generality</a></li>
</ul></li>
<li class="part"><span><b>IV RESAMPLING METHOD</b></span></li>
<li class="chapter" data-level="13" data-path="an-overview-of-resampling-methods.html"><a href="an-overview-of-resampling-methods.html"><i class="fa fa-check"></i><b>13</b> An Overview of Resampling Methods</a></li>
<li class="chapter" data-level="14" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>14</b> Cross-Validation</a>
<ul>
<li class="chapter" data-level="14.1" data-path="cross-validation.html"><a href="cross-validation.html#test-and-training-error-rate"><i class="fa fa-check"></i><b>14.1</b> Test and Training Error Rate</a></li>
<li class="chapter" data-level="14.2" data-path="cross-validation.html"><a href="cross-validation.html#vsa"><i class="fa fa-check"></i><b>14.2</b> The Validation Set Approach</a></li>
<li class="chapter" data-level="14.3" data-path="cross-validation.html"><a href="cross-validation.html#LOOCV"><i class="fa fa-check"></i><b>14.3</b> Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="14.4" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>14.4</b> <span class="math inline">\(k\)</span>-Fold Cross-Validation</a></li>
<li class="chapter" data-level="14.5" data-path="cross-validation.html"><a href="cross-validation.html#bias-variance-trade-off-for-k-fold-cross-validation"><i class="fa fa-check"></i><b>14.5</b> Bias-Variance Trade-Off for k-Fold Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i><b>15</b> The Bootstrap</a></li>
<li class="divider"></li>
<li><a href="https://github.com/ndleah/stat-learning" target="blank">View my GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<link href="style.css" rel="stylesheet">
<div class="hero-image-container"> 
  <img class= "hero-image" src="img/illos/cover.png">
</div>
<div id="LINEAR-REGRESSION" class="section level1" number="4">
<h1><span class="header-section-number">Section 4</span> Simple Linear Regression</h1>
<center>
<img src="img/illos/02-slg.png" />
</center>
<p><mark class="def">Simple linear regression</mark> is a very straightforward approach for predicting a qualitative response <span class="math inline">\(Y\)</span> on the basis of a single predictor <span class="math inline">\(X\)</span>. Mathematically, we can write this linear relationship as equation <a href="LINEAR-REGRESSION.html#eq:lr">(4.1)</a>:</p>
<div class="formula">
<p><span class="math display" id="eq:lr">\[\begin{equation}
\Large Y \approx \beta_0 + \beta_1 X
\tag{4.1} 
\end{equation}\]</span></p>
</div>
<p>Whereas:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>: intercept</li>
<li><span class="math inline">\(\beta_1\)</span>: slope</li>
</ul>
<div id="estimating-the-coefficients" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Estimating the Coefficients</h2>
<p>In practice, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown. So before make predictions, we must use data to estimate the coefficients. Let <span class="math inline">\((x_1, Y_1), (x_2, Y_2),...,(x_n, Y_n)\)</span> represent <span class="math inline">\(n\)</span> observation pairs, each of which consists of a measurement of <span class="math inline">\(X\)</span> and a measurement of <span class="math inline">\(Y\)</span>.</p>
<p>Our goal is to obtain coefficient estimates <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> such that the linear model fits the available data well. In other words, we want to find an intercept <span class="math inline">\(\beta_0\)</span> and a slope <span class="math inline">\(\beta_1\)</span> such that the resulting line is as close as possible to the <span class="math inline">\(n\)</span> data points. Figure <a href="LINEAR-REGRESSION.html#fig:regression">4.1</a> illustrated the oveview of linear regression elements.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:regression"></span>
<img src="img/regression.png" alt="Regression Line" width="80%" />
<p class="caption">
Figure 4.1: Regression Line
</p>
</div>
<p>There are numbers of ways of measuring <em>closeness</em>. However, by far the most common approach involves minimizing the <em>least squares</em> criterion, and we take that approach in this chapter.</p>
<p>Let <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i\)</span> be the prediction for <span class="math inline">\(Y\)</span> based on the <span class="math inline">\(i\)</span>th value of <span class="math inline">\(X\)</span>. Then <span class="math inline">\(e_i = y_i -\hat{y}+i\)</span> represents the <span class="math inline">\(i\)</span>th <em>residual</em> - this is the difference between the <span class="math inline">\(i\)</span>th value and the <span class="math inline">\(i\)</span>th reponse value that is predicted by our linear model. We define the <strong><em>residual sum of square (RSS)</em></strong> as <a href="LINEAR-REGRESSION.html#eq:rss">(4.2)</a> equation:</p>
<div class="formula">
<p><span class="math display" id="eq:rss">\[\begin{equation}
\Large RSS = e_1^2 + e_2^2 + ... + e_n^2
\tag{4.2} 
\end{equation}\]</span></p>
</div>
<p>or equivalent as <a href="LINEAR-REGRESSION.html#eq:rss2">(4.3)</a>:</p>
<div class="formula">
<p><span class="math display" id="eq:rss2">\[\begin{equation}
RSS = (y_1 - \hat{\beta_0} - \hat{\beta_1}x_2)^2 + (y_2 - \hat{\beta_0} - \hat{\beta_1}x_2)^2  + ... + (y_n - \hat{\beta_0} - \hat{\beta_1}x_n)^2
\tag{4.3} 
\end{equation}\]</span></p>
</div>
<p><strong><em>The least square approach</em></strong> chooses <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> to minimize the RSS.</p>
</div>
<div id="assessing-the-accuracy-of-the-coefficient-estimates" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Assessing the Accuracy of the Coefficient Estimates</h2>
<div id="population-regression-line" class="section level3 unnumbered">
<h3>Population Regression Line</h3>
<div class="formula">
<p><span class="math display" id="eq:prl">\[\begin{equation}
\Large Y=\beta_0 + \beta_1X + \epsilon
\tag{4.4}
\end{equation}\]</span></p>
</div>
<p>where <span class="math inline">\(\epsilon\)</span> mean zero random error term.</p>
</div>
<div id="least-squares-line" class="section level3 unnumbered">
<h3>Least Squares Line</h3>
<div class="formula">
<p><span class="math display" id="eq:lsl">\[\begin{equation}
\Large \hat{y}=\hat{\beta_0} + \hat{\beta_1}X 
\tag{4.5}
\end{equation}\]</span></p>
</div>
<p>true relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> takes the form <span class="math inline">\(Y=f(X)+\epsilon\)</span>.</p>
<p>Fundamentally, the concept of these two lines (<a href="#Population-Regression-Line">Population Regression Line</a> vs. <a href="#Least-Squares-Line">Least Squares Line</a>) is a natural extension of the standard statistical approach of using information from a sample to estimate characteristics of a large population.</p>
<p>For example, suppose that we are interested in knowing the population mean <span class="math inline">\(\mu\)</span> of some random variable <span class="math inline">\(Y\)</span>. Unfortunately, <span class="math inline">\(\mu\)</span> is unknown, but we do have access to <span class="math inline">\(n\)</span> observations from <span class="math inline">\(Y\)</span>, which we can write as <span class="math inline">\(y_1\)</span>, <span class="math inline">\(y_2\)</span>, <span class="math inline">\(\cdots\)</span>, <span class="math inline">\(y_n\)</span>, and which we can use to estimate <span class="math inline">\(\mu\)</span>. A reasonable estimate is <span class="math inline">\(\hat{\mu}\)</span> = <span class="math inline">\(\hat{y}\)</span>, where <span class="math inline">\(\hat{y} = \dfrac {1}{n}\sum^n_{i=1}{y_i}\)</span> is the sample mean.</p>
<p>The sample mean and the population mean are different, but in general the sample mean will provide a good estimate of the population mean. In the same way, the unknown coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in linear regression define the population regression line. We seek to estimate these unknown coefficients using  and  given in <a href="LINEAR-REGRESSION.html#eq:lsl">(4.5)</a>. These coefficient estimates define the least squares line.</p>
<p>The analogy between linear regression and estimation of the mean of a random variable is an apt one based on the concept of bias. If we use the sample mean <span class="math inline">\(\hat{\mu}\)</span> to estimate <span class="math inline">\(\mu\)</span>, this estimate is unbiased, in the sense that on average, we expect <span class="math inline">\(\hat{\mu}\)</span> to equal <span class="math inline">\(\mu\)</span>.</p>
<p>In other words, if we estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> on the basis of a particular data set, then our estimates won’t be exactly equal to <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. But if we could average the estimates obtained over a huge number of data sets, then the average of these estimates would be spot on!</p>
<p>In fact, we can see from the right-hand panel of Figure <a href="LINEAR-REGRESSION.html#fig:simulated">4.2</a> that the average of many least squares lines, each estimated from a separate data set, is pretty close to the true population regression line.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:simulated"></span>
<img src="img/fig3.3.png" alt="A simulated data set" width="80%" />
<p class="caption">
Figure 4.2: A simulated data set
</p>
</div>
<p>As isllutrated in Figure <a href="LINEAR-REGRESSION.html#fig:simulated">4.2</a>:</p>
<ul>
<li><p><strong>Left:</strong> The red line represents the true relationship, <span class="math inline">\(f(X) = 2+3X\)</span>, which is known as the population regression line. The blue line is the least squares line; it is the least squares estimate for <span class="math inline">\(f(X)\)</span> based on the observed data, shown in black.</p></li>
<li><p><strong>Right:</strong> The population regression line is again shown in red, and the least squares line in dark blue. In light blue, ten least squares lines are shown, each computed on the basis of a separate random set of observations. Each least squares line is different, but on average, the least squares lines are quite close to the population regression line.</p></li>
</ul>
</div>
<div id="how-accurate-is-the-sample-mean-hatmu-as-an-estimate-of-population-mean-mu" class="section level3 unnumbered">
<h3><mark class="quest"> How Accurate Is The Sample Mean <span class="math inline">\(\hat{\mu}\)</span> As An Estimate Of Population Mean <span class="math inline">\(\mu\)</span> </mark></h3>
<p>We answer this question by computing the <strong><em>standard error</em></strong> of <span class="math inline">\(\mu\)</span>, written as SE(<span class="math inline">\(\hat{\mu}\)</span>).</p>
<p>Standard errors can also be used to perform <strong><em>hypothesis tests</em></strong> on the coefficients. The most common hypothesis test involves testing the <strong><em>null hypothesis</em></strong> of</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: There is no relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></li>
<li><span class="math inline">\(H_a\)</span>: There is some relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></li>
</ul>
<p>Mathematically, this corresponds to testing</p>
<p><span class="math display">\[\begin{equation}
H_0: \beta_1 = 0
\end{equation}\]</span></p>
<p>versus</p>
<p><span class="math display">\[\begin{equation}
H_1: \beta_1 \neq 0
\end{equation}\]</span>
If <span class="math inline">\(\beta_1 = 0\)</span> then the model reduces to <span class="math inline">\(Y=\beta_0+\epsilon\)</span>, and <span class="math inline">\(X\)</span> is not associated with <span class="math inline">\(Y\)</span>.</p>
<p>To test the null hypothesis, we need to determine whether <span class="math inline">\(\hat{\beta_1}\)</span>, our estimate for <span class="math inline">\(\beta_1\)</span>, is sufficiently far from zero that we can be confident that <span class="math inline">\(\beta_1\)</span> is non-zero.</p>
</div>
<div id="how-far-is-far-enough" class="section level3 unnumbered">
<h3><mark class="quest"> How Far Is Far Enough? </mark></h3>
<p>This is course depends on the accuracy of <span class="math inline">\(\hat{\beta_1}\)</span> -that is, it depends on <span class="math inline">\(SE(\hat{\beta_1})\)</span>. If SE(<span class="math inline">\(\hat{\beta_1}\)</span>) is small, then even relatively small values of <span class="math inline">\(\hat{\beta_1}\)</span> may provide strong evidence that <span class="math inline">\(\beta_1 \neq 0\)</span>​, and hence that there is a relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. In contrast, if SE(<span class="math inline">\(\hat{\beta_1}\)</span>) is large, then <span class="math inline">\(\hat{\beta_1}\)</span> must be large in absolute value in order for us to reject the null hypothesis.</p>
</div>
<div id="t-distribution" class="section level3 unnumbered">
<h3>T-distribution</h3>
<p>The <mark class="def">T-distribution</mark> describes the standardized distances of sample means to the population mean when the population standard deviation is not known, and the observations come from a normally distributed population.</p>
<p>In practice, we compute a <mark class="def">t-statistic</mark>, given by</p>
<div class="formula">
<p><span class="math display">\[\begin{equation}
\Large t=\dfrac{\hat{\beta_1}-0}{SE(\hat{\beta_1})}
\end{equation}\]</span></p>
</div>
<p>For example, we have a t-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom as in Figure <a href="LINEAR-REGRESSION.html#fig:tstat">4.3</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tstat"></span>
<img src="img/tstat.png" alt="Sampling Distribution of Test Statistic" width="65%" />
<p class="caption">
Figure 4.3: Sampling Distribution of Test Statistic
</p>
</div>
<p>The t-distribution has a bell shape and for values of n greater than approximately 30 it is quite similar to the normal distribution. Consequently, it is a simple matter to compute probability of observing any value equal to <span class="math inline">\(|t|\)</span> or larger, assuming <span class="math inline">\(\beta_1 =0\)</span>. We call this probability the <mark class="def">p-value</mark>.</p>
<div class="formula">
<p><span class="math display">\[\begin{equation}
\Large P(|T| &gt; t) = p
\end{equation}\]</span></p>
</div>
<p>Roughly speaking, we interpret the <strong><em>p-value</em></strong> as follows:</p>
<p>If we see a small p-value, then we can infer that there is an association between the predictor and the response. We reject the null hypothesis-that is, we declare a relationship to exist between X and Y- if the p-value is small enough.</p>
<p>Typical p-value cutoffs for rejecting the null hypothesis are 5 or 1%. When <span class="math inline">\(n\)</span> = 30, these corresponds to t-statistics of around 2 and 2.75, respectively.</p>
</div>
</div>
<div id="assessing-the-accuracy-of-the-model" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Assessing the Accuracy of the Model</h2>
<p>After we have rejected the null hypothesis, t is natural to want to quantify the <em>extend of the model fits the data</em>.</p>
<p>The quality of a linear regression fit is typically assessed using 2 related quantities: the <em>residual standard error</em> and the <span class="math inline">\(R^2\)</span> statistic.</p>
<div id="residual-standard-error" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Residual Standard Error</h3>
<p>The <mark class="def">Residual Standard Error</mark> (RSE) is an estimation of the standard deviation of <span class="math inline">\(\epsilon\)</span>. Roughly speaking, it is the average amount that the response will deviate from the true regression line. It is computed using <a href="LINEAR-REGRESSION.html#eq:rse">(4.6)</a>:</p>
<div class="formula">
<p><span class="math display" id="eq:rse">\[\begin{equation}
RSE=\sqrt{\frac{1}{n-2}} RSS=\sqrt{\frac{1}{n-2}{\sum_{i=1}^n (y_{i} - \hat{y_1})^{2}}}
\tag{4.6} 
\end{equation}\]</span></p>
</div>
<p>The RSE is considered a measure of the <em>lack of fit</em> of the model to the data:</p>
<ul>
<li><p>If RSE is small, we can conclude that the model fits the data very well.</p></li>
<li><p>In contrast, if RSE is large, it indicates that the model doesn’t fit the data well.</p></li>
</ul>
<div class="tip">
<p>One consideration of RSE is it is the measure in the units of <span class="math inline">\(Y\)</span> and thus, the method is not always clear what constitute a good RSE.</p>
</div>
</div>
<div id="r2-standard-error" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> <span class="math inline">\(R^2\)</span> Standard Error</h3>
<p>The <mark class="def"><span class="math inline">\(R^2\)</span> statistic</mark> takes the form of a <em>proportion</em> - the proportion of variance explained-and so it always takes on a value between 0 and 1, and is independent of the scale of <span class="math inline">\(Y\)</span>. To calculate <span class="math inline">\(R^2\)</span>, we use the formula <a href="LINEAR-REGRESSION.html#eq:r2">(4.7)</a>:</p>
<div class="formula">
<p><span class="math display" id="eq:r2">\[\begin{equation}
\Large R^2 = \frac{TSS}{TSS−RSS}=1−\frac{TSS}{RSS}
\tag{4.7} 
\end{equation}\]</span></p>
</div>
<p>Whereas:</p>
<ul>
<li><strong>TSS</strong>: total sum of square.</li>
<li><strong>RSS</strong>: measures the amount of variability that is left unexplained after performing the regression.</li>
</ul>
<p>In terms of evaluating the <span class="math inline">\(R^2\)</span> statistic result:</p>
<ul>
<li><span class="math inline">\(R^2\)</span> statistic close to 1 - the model fits well.</li>
<li><span class="math inline">\(R^2\)</span> statistic close to 0 - the model does not fit well.</li>
</ul>
</div>
</div>
<div id="consideration" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Consideration</h2>
<p><mark class="quest">Simple linear regression</mark> is a useful approach for predicting a response on the basis of a single predictor variable. However, in practice we often have more than one predictor.</p>
<p>The solution for this is to use another linear regression named as <mark class="quest">Multiple Linear Regression</mark>, which will be discussed in the next section.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="assessing-model-accuracy.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
