<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 11 Generative Models for Classification | Statistics Learning</title>
  <meta name="description" content="Section 11 Generative Models for Classification | Statistics Learning" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 11 Generative Models for Classification | Statistics Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https//:www.ndleah.github.io/stat-learning/" />
  <meta property="og:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />
  
  <meta name="github-repo" content="ndleah/stat-learning" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 11 Generative Models for Classification | Statistics Learning" />
  
  
  <meta name="twitter:image" content="https//:www.ndleah.github.io/stat-learning//img/illos/cover.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/illos/favicon.ico" type="image/x-icon" />
<link rel="prev" href="logistic-regression.html"/>
<link rel="next" href="a-comparison-of-classification-methods.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="img/illos/logo_2.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>I STATISTICAL LEARNING</b></span></li>
<li class="chapter" data-level="1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html"><i class="fa fa-check"></i><b>1</b> What is Statistical Learning?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#why-estimate-f"><i class="fa fa-check"></i><b>1.1</b> Why Estimate f?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#prediction"><i class="fa fa-check"></i><b>1.1.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>1.2</b> How Do We Estimate f?</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#parametric-methods"><i class="fa fa-check"></i><b>1.2.1</b> Parametric Methods</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#non-parametric-methods"><i class="fa fa-check"></i><b>1.2.2</b> Non-Parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#the-tradeoff-between-prediction-accuracy-and-model-interpretability"><i class="fa fa-check"></i><b>1.3</b> The Tradeoff Between Prediction Accuracy and Model Interpretability</a></li>
<li class="chapter" data-level="1.4" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#supervised-vs.-unsupervised-learning"><i class="fa fa-check"></i><b>1.4</b> Supervised Vs. Unsupervised Learning</a></li>
<li class="chapter" data-level="1.5" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html#regression-vs.-classification"><i class="fa fa-check"></i><b>1.5</b> Regression Vs. Classification</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html"><i class="fa fa-check"></i><b>2</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-regression-setting"><i class="fa fa-check"></i><b>2.1</b> The Regression Setting</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>2.1.1</b> Measuring the Quality of fit</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2</b> The Bias-Variance Trade-Off</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Variance-Error"><i class="fa fa-check"></i><b>2.2.1</b> Variance Error</a></li>
<li class="chapter" data-level="2.2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#Bias-Error"><i class="fa fa-check"></i><b>2.2.2</b> Bias Error</a></li>
<li class="chapter" data-level="2.2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bias-variance-trafe-off"><i class="fa fa-check"></i><b>2.2.3</b> Bias-Variance Trafe-Off</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-classification-setting"><i class="fa fa-check"></i><b>2.3</b> The Classification Setting</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#bayes"><i class="fa fa-check"></i><b>2.3.1</b> The Bayes Classifier</a></li>
<li class="chapter" data-level="2.3.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#KNN"><i class="fa fa-check"></i><b>2.3.2</b> K-Nearest Neighbors (KNN)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II LINEAR REGRESSION{#LINEAR-REGRESSION}</b></span></li>
<li class="chapter" data-level="3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>3.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#assessing-the-accuracy-of-the-coefficient-estimates"><i class="fa fa-check"></i><b>3.2</b> Assessing the Accuracy of the Coefficient Estimates</a>
<ul>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#population-regression-line"><i class="fa fa-check"></i>Population Regression Line</a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-line"><i class="fa fa-check"></i>Least Squares Line</a></li>
<li><a href="simple-linear-regression.html#how-accurate-is-the-sample-mean-hatmu-as-an-estimate-of-population-mean-mu"><mark class="quest"> How Accurate Is The Sample Mean <span class="math inline">\(\hat{\mu}\)</span> As An Estimate Of Population Mean <span class="math inline">\(\mu\)</span> </mark></a></li>
<li><a href="simple-linear-regression.html#how-far-is-far-enough"><mark class="quest"> How Far Is Far Enough? </mark></a></li>
<li class="chapter" data-level="" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#t-distribution"><i class="fa fa-check"></i>T-distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#assessing-the-accuracy-of-the-model"><i class="fa fa-check"></i><b>3.3</b> Assessing the Accuracy of the Model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residual-standard-error"><i class="fa fa-check"></i><b>3.3.1</b> Residual Standard Error</a></li>
<li class="chapter" data-level="3.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#r2-standard-error"><i class="fa fa-check"></i><b>3.3.2</b> <span class="math inline">\(R^2\)</span> Standard Error</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#consideration"><i class="fa fa-check"></i><b>3.4</b> Consideration</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Response-and-Predictors-Relationships"><i class="fa fa-check"></i><b>4.1</b> Response and Predictors Relationships</a></li>
<li class="chapter" data-level="4.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Dealing-With-Large-Number-Of-Variables"><i class="fa fa-check"></i><b>4.2</b> Dealing With Large Number Of Variables</a></li>
<li class="chapter" data-level="4.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#Model-Fit"><i class="fa fa-check"></i><b>4.3</b> Model Fit</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html"><i class="fa fa-check"></i><b>5</b> Other Considerations in the Regression Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-linearity-of-the-Data"><i class="fa fa-check"></i><b>5.1</b> Non-linearity of the Data</a></li>
<li class="chapter" data-level="5.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#corre-error-term"><i class="fa fa-check"></i><b>5.2</b> Correlation of Error Terms</a></li>
<li class="chapter" data-level="5.3" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Non-Constant-Variance-of-Error-Terms"><i class="fa fa-check"></i><b>5.3</b> Non-constant Variance of Error Terms (Heteroscedasticity)</a></li>
<li class="chapter" data-level="5.4" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Outlier"><i class="fa fa-check"></i><b>5.4</b> Outlier</a></li>
<li class="chapter" data-level="5.5" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#High-Leverage-Points"><i class="fa fa-check"></i><b>5.5</b> High Leverage Points</a></li>
<li class="chapter" data-level="5.6" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#Collinearity"><i class="fa fa-check"></i><b>5.6</b> Collinearity</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#correlation-matrix"><i class="fa fa-check"></i><b>5.6.1</b> Correlation Matrix</a></li>
<li class="chapter" data-level="5.6.2" data-path="other-considerations-in-the-regression-model.html"><a href="other-considerations-in-the-regression-model.html#variance-inflation-factor-vif"><i class="fa fa-check"></i><b>5.6.2</b> Variance Inflation Factor (VIF)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html"><i class="fa fa-check"></i><b>6</b> Case Study - Marketing Plan</a>
<ul>
<li class="chapter" data-level="6.1" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#data-overview"><i class="fa fa-check"></i><b>6.1</b> Data Overview</a></li>
<li class="chapter" data-level="6.2" data-path="case-study---marketing-plan.html"><a href="case-study---marketing-plan.html#important-questions"><i class="fa fa-check"></i><b>6.2</b> Important Questions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Lab: Linear Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>7.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="7.2" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#multiple-linear-regression-1"><i class="fa fa-check"></i><b>7.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="7.3" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#interaction-terms"><i class="fa fa-check"></i><b>7.3</b> Interaction Terms</a></li>
<li class="chapter" data-level="7.4" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#non-linear-transformations-of-the-predictors"><i class="fa fa-check"></i><b>7.4</b> Non-linear Transformations of the Predictors</a></li>
<li class="chapter" data-level="7.5" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#qualitative-predictors"><i class="fa fa-check"></i><b>7.5</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="7.6" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#writing-functions"><i class="fa fa-check"></i><b>7.6</b> Writing Functions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>8</b> Exercises</a></li>
<li class="part"><span><b>III CLASSIFICATION</b></span></li>
<li class="chapter" data-level="9" data-path="an-overview-of-classification.html"><a href="an-overview-of-classification.html"><i class="fa fa-check"></i><b>9</b> An Overview of Classification</a></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-model"><i class="fa fa-check"></i><b>10.1</b> Logistic Model</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#estimating-the-regression-coefficients"><i class="fa fa-check"></i><b>10.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>10.3</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="10.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>10.4</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html"><i class="fa fa-check"></i><b>11</b> Generative Models for Classification</a>
<ul>
<li class="chapter" data-level="11.1" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#Linear-Discriminant-Analysis"><i class="fa fa-check"></i><b>11.1</b> Linear Discriminant Analysis</a>
<ul>
<li><a href="generative-models-for-classification.html#a.-when-p-1">a. When <span class="math inline">\(p\)</span> = 1</a></li>
<li><a href="generative-models-for-classification.html#b.-when-p-1">b. When <span class="math inline">\(p\)</span> &gt; 1</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#c.-problems-with-lda"><i class="fa fa-check"></i>c. Problems with LDA</a></li>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#d.-confusion-matrix"><i class="fa fa-check"></i>d. Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#QDA"><i class="fa fa-check"></i><b>11.2</b> Quadratic Discriminant Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html#why-is-this-important"><i class="fa fa-check"></i>Why is this important?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html"><i class="fa fa-check"></i><b>12</b> A Comparison of Classification Methods</a>
<ul>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-1-2-3"><i class="fa fa-check"></i>Figure for Scenarios 1, 2, 3</a></li>
<li class="chapter" data-level="12.1" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-1"><i class="fa fa-check"></i><b>12.1</b> Scenario 1</a></li>
<li class="chapter" data-level="12.2" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-2"><i class="fa fa-check"></i><b>12.2</b> Scenario 2</a></li>
<li class="chapter" data-level="12.3" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-3"><i class="fa fa-check"></i><b>12.3</b> Scenario 3</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#figure-for-scenarios-4-5-6"><i class="fa fa-check"></i>Figure for Scenarios 4, 5, 6</a></li>
<li class="chapter" data-level="12.4" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-4"><i class="fa fa-check"></i><b>12.4</b> Scenario 4</a></li>
<li class="chapter" data-level="12.5" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-5"><i class="fa fa-check"></i><b>12.5</b> Scenario 5</a></li>
<li class="chapter" data-level="12.6" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#scenario-6"><i class="fa fa-check"></i><b>12.6</b> Scenario 6</a></li>
<li class="chapter" data-level="" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#conclusion"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html"><i class="fa fa-check"></i><b>13</b> Generalized Linear Model</a>
<ul>
<li class="chapter" data-level="13.1" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#overview"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html#generalized-linear-models-in-greater-generality"><i class="fa fa-check"></i><b>13.2</b> Generalized Linear Models in Greater Generality</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html"><i class="fa fa-check"></i><b>14</b> Lab: Classification Methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#the-stock-market-data"><i class="fa fa-check"></i><b>14.1</b> The Stock Market Data</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-1"><i class="fa fa-check"></i><b>14.1.1</b> Data Overview</a></li>
<li class="chapter" data-level="14.1.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#logistic-regression-1"><i class="fa fa-check"></i><b>14.1.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="14.1.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>14.1.3</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="14.1.4" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>14.1.4</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="14.1.5" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#naive-bayes"><i class="fa fa-check"></i><b>14.1.5</b> Naive Bayes</a></li>
<li class="chapter" data-level="14.1.6" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>14.1.6</b> K-Nearest Neighbors</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#the-caravan-insurance-data"><i class="fa fa-check"></i><b>14.2</b> The Caravan Insurance Data</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-2"><i class="fa fa-check"></i><b>14.2.1</b> Data Overview</a></li>
<li class="chapter" data-level="14.2.2" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#k-nearest-neighbors-1"><i class="fa fa-check"></i><b>14.2.2</b> K-Nearest Neighbors</a></li>
<li class="chapter" data-level="14.2.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#logistics-regression"><i class="fa fa-check"></i><b>14.2.3</b> Logistics Regression</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#bikeshare-data"><i class="fa fa-check"></i><b>14.3</b> Bikeshare Data</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html#data-overview-3"><i class="fa fa-check"></i><b>14.3.1</b> Data Overview</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV RESAMPLING METHOD</b></span></li>
<li class="chapter" data-level="15" data-path="an-overview-of-resampling-methods.html"><a href="an-overview-of-resampling-methods.html"><i class="fa fa-check"></i><b>15</b> An Overview of Resampling Methods</a></li>
<li class="chapter" data-level="16" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>16</b> Cross-Validation</a>
<ul>
<li class="chapter" data-level="16.1" data-path="cross-validation.html"><a href="cross-validation.html#test-and-training-error-rate"><i class="fa fa-check"></i><b>16.1</b> Test and Training Error Rate</a></li>
<li class="chapter" data-level="16.2" data-path="cross-validation.html"><a href="cross-validation.html#the-validation-set-approach"><i class="fa fa-check"></i><b>16.2</b> The Validation Set Approach</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/ndleah/stat-learning" target="blank">View my GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<link href="style.css" rel="stylesheet">
<div class="hero-image-container"> 
  <img class= "hero-image" src="img/illos/cover.png">
</div>
<div id="generative-models-for-classification" class="section level1" number="11">
<h1><span class="header-section-number">Section 11</span> Generative Models for Classification</h1>
/*
<center>
<img src="img/illos/03-gm.png" />
</center>
<p>*/</p>
<p>Why do we need another method, when we have logistic regression? There are several reasons:</p>
<ul>
<li><p>When there is substantial separation between the two classes, the parameter estimates for the logistic regression model are surprisingly unstable. The methods that we consider in this section do not suffer from this problem.</p></li>
<li><p>If the distribution of the predictors X is approximately normal in each of the classes and the sample size is small, then the approaches in this section may be more accurate than logistic regression.</p></li>
<li><p>The methods in this section can be naturally extended to the case of more than two response classes. (In the case of more than two response classes, we can also use multinomial logistic regression.)</p></li>
</ul>
<p>Suppose that we wish to classify an observation into one of <span class="math inline">\(K\)</span> classes, where <span class="math inline">\(K ≥ 2\)</span>. Then Bayes’ theorem states that:</p>
<div class="formula">
<p><span class="math display">\[
\Large \Pr(A|B)=\frac{\Pr(B|A)\Pr(A)}{\Pr(B|A)\Pr(A)+\Pr(B|\neg A)\Pr(\neg A)}
\]</span></p>
</div>
<p>In the following sections, we discuss three classifiers that use different estimates of <span class="math inline">\(f_k(x)\)</span> to approximate the Bayes classifier:
1. <em>linear discriminant analysis</em>
2. <em>quadratic discriminant analysis</em>
3. <em>naive Bayes</em></p>
<div id="Linear-Discriminant-Analysis" class="section level2" number="11.1">
<h2><span class="header-section-number">11.1</span> Linear Discriminant Analysis</h2>
<div id="a.-when-p-1" class="section level3 unnumbered">
<h3>a. When <span class="math inline">\(p\)</span> = 1</h3>
<p>For now, assume that <span class="math inline">\(p\)</span> = 1—that is, we have only one predictor. We will then classify an observation to the class for which pk(x) is greatest. To estimate <span class="math inline">\(f_k(x)\)</span>, we will first <strong>make some assumptions about its form</strong>: In particular, we assume that <span class="math inline">\(f_k(x)\)</span> is <em>normal</em> or <em>Gaussian</em>.</p>
<p>In practice, even if we are quite certain of our assumption that <span class="math inline">\(X\)</span> is drawn from a Gaussian distribution within each class, to apply the Bayes classifier we still have to estimate the parameters <span class="math inline">\(\mu_1, . . . ,\mu_K\)</span>, <span class="math inline">\(\pi_1, . . . ,\pi_K\)</span>, and <span class="math inline">\(\sigma^2\)</span>. The <em><strong>linear discriminant analysis (LDA)</strong></em> method approximates the Bayes classifier by plugging estimates for <span class="math inline">\(\pi_k, \mu_k\)</span>, and <span class="math inline">\(\sigma^2\)</span>.</p>
<p>To reiterate, the LDA classifier results from assuming that the observations within each class come from a normal distribution with a class-specific mean and a common variance <span class="math inline">\(\sigma^2\)</span>, and plugging estimates for these parameters into the Bayes classifier.</p>
</div>
<div id="b.-when-p-1" class="section level3 unnumbered">
<h3>b. When <span class="math inline">\(p\)</span> &gt; 1</h3>
<p>We now extend the LDA classifier to the case of multiple predictors. To do this, we will assume that <span class="math inline">\(X = (X_1,X_2, . . . ,X_p)\)</span> is drawn from a multivariate Gaussian (or multivariate normal) distribution, with a class-specific mean vector and a common covariance matrix.</p>
<p>The <em><strong>multivariate Gaussian distribution</strong></em> assumes that each individual predictor follows a one-dimensional normal distribution.</p>
</div>
<div id="c.-problems-with-lda" class="section level3 unnumbered">
<h3>c. Problems with LDA</h3>
</div>
<div id="d.-confusion-matrix" class="section level3 unnumbered">
<h3>d. Confusion Matrix</h3>
<p>A <strong><em>confusion matrix</em></strong> is a summarized table of the number of correct and incorrect predictions (or actual and predicted values) yielded by a classifier (or classification model) for binary classification tasks.</p>
<div class="tip">
<p>In simple words, “ A confusion matrix is a performance measurement for machine learning algorithm”.</p>
</div>
<p>By visualizing the confusion matrix, an individual could determine the accuracy of the model by observing the diagonal values for measuring the number of accurate classification.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hello"></span>
<img src="img/cm.png" alt="A sample 2x2 confusion matrix" width="50%" />
<p class="caption">
Figure 11.1: A sample 2x2 confusion matrix
</p>
</div>
<p>see figure <a href="generative-models-for-classification.html#fig:hello">11.1</a></p>
<div id="i.-true-positive-true-negative-false-positive-and-false-negative" class="section level4 unnumbered">
<h4>i. True Positive, True Negative, False Positive and False Negative</h4>
<p><br></p>
<div class="def">
<div class="split">
<div class="split1">
<p><mark class="def">true positive</mark></p>
<p>is an outcome where the model correctly predicts the positive class,</p>
</div>
<div class="split2">
<p><mark class="def">true negative</mark></p>
<p>is an outcome where the model correctly predicts the negative class.</p>
</div>
</div>
<div class="split">
<div class="split1">
<p><mark class="def">false positive</mark> (<em>Type I Error</em>)</p>
<p>is an outcome where the model incorrectly predicts the positive class when the actual class is negative.</p>
</div>
<div class="split2">
<p><mark class="def">false negative</mark> (<em>Type II Error</em>)</p>
<p>is an outcome where the model incorrectly predicts the negative class when the actual class is positive.</p>
</div>
</div>
</div>
<p></br></p>
</div>
<div id="ii.-precision" class="section level4 unnumbered">
<h4>ii. Precision</h4>
<p><strong><em>Precision</em></strong> explains how many correctly predicted values came out to be positive actually. Or simply it gives the number of correct outputs given by the model out of all the correctly predicted positive values by the model.</p>
<p>It determines whether a model is reliable or not. It is useful for the conditions where false positive is a higher concern as compared to a false negative. For calculating the precision, the formula is:</p>
<div class="formula">
<p><span class="math display">\[
\Large \Large Precision = \frac{TP}{TP+FP}
\]</span></p>
</div>
</div>
<div id="iii.-recall" class="section level4 unnumbered">
<h4>iii. Recall</h4>
<p><strong><em>Recall</em></strong> describes how many of the actual positive values to be predicted correctly out of the model. It is useful when false-negative dominates false positives. The formula for calculating the recall is</p>
<div class="formula">
<p><span class="math display">\[
\Large Recall = \frac{TP}{TP+FN}
\]</span></p>
</div>
<div class="hat">
<p>Increasing precision decreases recall and vice versa, this is known as the <strong>precision/recall tradeoff</strong>.</p>
</div>
</div>
<div id="iv.-accuracy" class="section level4 unnumbered">
<h4>iv. Accuracy</h4>
<p>One of the significant parameters in determining the <strong><em>accuracy</em></strong> of the classification problems, it explains how regularly the model predicts the correct outputs and can be measured as the ratio of the number of correct predictions made by the classifier over the total number of predictions made by the classifiers. The formula is</p>
<div class="formula">
<p><span class="math display">\[
\Large Accuracy = \frac{TP+TN}{TP+TN+FP+FN}
\]</span></p>
</div>
</div>
<div id="v.-f-measure" class="section level4 unnumbered">
<h4>v. F-Measure</h4>
<p>For the condition when two models have low precision and high recall or vice versa, it becomes hard to compare those models, therefore to solve this issue we can deploy <strong><em>F-score</em></strong>.</p>
<p>::tip
“F-score is a harmonic mean of Precision and Recall”.
:::</p>
<p>By calculating F-score, we can evaluate the recall and precision at the same time. Also, if the recall is equal to precision, The F-score is maximum and can be calculated using the below formula</p>
<div class="formula">
<p><span class="math display">\[
\Large F-measure = \frac{2 \times Recall \times precision}{Recall + Precision}
\]</span></p>
</div>
</div>
<div id="vi.-roc-curve" class="section level4 unnumbered">
<h4>vi. ROC curve</h4>
<p>The <strong><em>ROC curve</em></strong> is a popular graphic for simultaneously displaying the two types of errors for all possible thresholds.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-61"></span>
<img src="img/162-Figure4.8-1.png" alt="A ROC curve for the LDA classifier on the Default data" width="65%" />
<p class="caption">
Figure 11.2: A ROC curve for the LDA classifier on the Default data
</p>
</div>
<p>Figure above displays the ROC curve for the LDA classifier on the training data. The overall performance of a classifier, summarized over all possible thresholds, is given by the area under the (ROC) curve (AUC). An ideal ROC curve will hug the top left corner, so the large area under the (ROC) curve
the AUC the better the classifier. For this data the AUC is 0.95, which is close to the maximum of one so would be considered very good.</p>
</div>
</div>
</div>
<div id="QDA" class="section level2" number="11.2">
<h2><span class="header-section-number">11.2</span> Quadratic Discriminant Analysis</h2>
<p><strong><em>Quadratic discriminant analysis (QDA)</em></strong> provides an alternative approach. Like LDA, the QDA classifier assumes that the observations from each class of Y are drawn from a Gaussian distribution. However, unlike LDA, QDA assumes that each class has its own covariance matrix.</p>
<p>In other words, the predictor variables are not assumed to have common variance across each of the <span class="math inline">\(k\)</span> levels in <span class="math inline">\(Y\)</span>. Mathematically, it assumes that an observation from the <span class="math inline">\(k\)</span>th class is of the form, where is a covariance matrix for the <span class="math inline">\(k\)</span>th class. Under this assumption, the classifier assigns an observation to the class for which is largest.</p>
<div id="why-is-this-important" class="section level3 unnumbered">
<h3>Why is this important?</h3>
<p>Consider the image below. In trying to classify the observations into the three (color-coded) classes, LDA (left plot) provides linear decision boundaries that are based on the assumption that the observations vary consistently across all classes. However, when looking at the data it becomes apparent that the variability of the observations within each class differ. Consequently, QDA (right plot) is able to capture the differing covariances and provide more accurate non-linear classification decision boundaries.</p>
<p><img src="img/QDA.png" width="65%" style="display: block; margin: auto;" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="a-comparison-of-classification-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
